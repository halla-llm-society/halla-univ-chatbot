import asyncio
import os
from openai import OpenAI
from fastapi import APIRouter, HTTPException 
from pydantic import BaseModel
from dotenv import load_dotenv  
from fastapi.responses import StreamingResponse
from ..chatbotDirectory import chatbot
from ..chatbotDirectory.functioncalling import tools, FunctionCalling
from ..chatbotDirectory.functioncalling import model
from ..chatbotDirectory.chatbot import ChatbotStream
import json


# UserRequest í´ë˜ìŠ¤ì— language í•„ë“œ ì¶”ê°€
class UserRequest(BaseModel):
    message: str
    language: str = "KOR"  # ê¸°ë³¸ê°’ì€ í•œêµ­ì–´ë¡œ ì„¤ì •

func_calling = FunctionCalling(
    model=model.basic,
    available_functions={
        # í•„ìš”ì‹œ ë‹¤ë¥¸ í•¨ìˆ˜ë„ ì—¬ê¸°ì— ì¶”ê°€
    }
)
router = APIRouter()

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# ì˜ˆì‹œ: ì „ì—­ ë˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ ë‚´ë¶€ì—ì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
chatbot = ChatbotStream(
    model=model.advanced,
    system_role="""ë‹¹ì‹ ì€ í•™êµ ìƒí™œ, í•™ê³¼ ì •ë³´, í–‰ì‚¬ ë“± ì‚¬ìš©ìê°€ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì•„ëŠ” ë²”ìœ„ ì•ˆì—ì„œ ëŒ€ë‹µí•©ë‹ˆë‹¤. ë‹¨ ì ˆëŒ€ ê±°ì§“ë‚´ìš©ì„ ë§í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì•„ëŠ” ë²”ìœ„ì—ì„œ ë§í•˜ê³  ë¶€ì¡±í•œ ë¶€ë¶„ì€ ì¸ì •í•˜ì„¸ìš”.
    ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ê¸°ëŠ¥ì´ìˆìŠµë‹ˆë‹¤.
    ë‹¹ì‹ ì€ í•œë¼ëŒ€ ê³µì§€ì‚¬í•­ì„ íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ë‹¹ì‹ ì€ í•œë¼ëŒ€ í•™ì‹ë©”ë‰´ë¥¼ íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ë‹¹ì‹ ì€ í•œë¼ëŒ€ í•™ì‚¬ì¼ì •ì„ íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.""",
    instruction="ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.",
    user="í•œë¼ëŒ€ ëŒ€í•™ìƒ",
    assistant="memmo"
)

# ì±„íŒ…
class Message(BaseModel):
    message: str
    
@router.post("/chat")
async def stream_chat(user_input: UserRequest):
    # 1) ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì›ë³¸ ë¬¸ë§¥ì— ì¶”ê°€
    chatbot.add_user_message_in_context(user_input.message)

    # 2) ì–¸ì–´ ì§€ì¹¨ ì¶”ê°€
    instruction_map = {
        "KOR": "í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê³  ë”°ëœ»í•˜ê²Œ ë‹µí•´ì£¼ì„¸ìš”.",
        "ENG": "Please respond kindly in English.",
        "VI": "Vui lÃ²ng tráº£ lá»i báº±ng tiáº¿ng Viá»‡t má»™t cÃ¡ch nháº¹ nhÃ ng.",
        "JPN": "æ—¥æœ¬èªã§ä¸å¯§ã«æ¸©ã‹ãç­”ãˆã¦ãã ã•ã„ã€‚",
        "CHN": "è¯·ç”¨ä¸­æ–‡äº²åˆ‡åœ°å›ç­”ã€‚",
        "UZB": "Iltimos, oâ€˜zbek tilida samimiy va hurmat bilan javob bering.",
        "MNG": "ĞœĞ¾Ğ½Ğ³Ğ¾Ğ» Ñ…ÑĞ»ÑÑÑ€ ÑĞµĞ»Ğ´ÑĞ³, Ğ´ÑƒĞ»Ğ°Ğ°Ñ…Ğ°Ğ½ Ñ…Ğ°Ñ€Ğ¸ÑƒĞ»Ğ½Ğ° ÑƒÑƒ.",
        "IDN": "Tolong jawab dengan ramah dan hangat dalam bahasa Indonesia."
    }
    instruction = instruction_map.get(user_input.language, instruction_map["KOR"])
    chatbot.context[-1]["content"] += " " + instruction

    # 3) RAG ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    rag_ctx = chatbot.get_rag_context(user_input.message)
    has_rag = bool(rag_ctx and rag_ctx.strip())

    # 4) í•¨ìˆ˜ í˜¸ì¶œ ë¶„ì„ ë° ì‹¤í–‰
    analyzed = func_calling.analyze(user_input.message, tools)
    func_msgs: list[dict] = []
    func_outputs: list[str] = []

    for tool_call in analyzed:
        if getattr(tool_call, "type", None) != "function_call":
            continue
        func_name = tool_call.name
        func_args = json.loads(tool_call.arguments)
        call_id = tool_call.call_id

        func_to_call = func_calling.available_functions.get(func_name)
        if not func_to_call:
            print(f"[ì˜¤ë¥˜] ë“±ë¡ë˜ì§€ ì•Šì€ í•¨ìˆ˜: {func_name}")
            continue

        try:
            # ì•ˆì „ ê¸°ë³¸ê°’ ë³´ê°•
            if func_name == "get_halla_cafeteria_menu":
                func_args.setdefault("date", "ì˜¤ëŠ˜")
                # mealì€ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ë¼ë‹ˆë¥¼ ë°˜í™˜

            func_response = (
                func_to_call(chat_context=chatbot.context[:], **func_args)
                if func_name == "search_internet"
                else func_to_call(**func_args)
            )

            func_msgs.extend([
                {
                    "type": "function_call",
                    "call_id": call_id,
                    "name": func_name,
                    "arguments": tool_call.arguments,
                },
                {
                    "type": "function_call_output",
                    "call_id": call_id,
                    "output": str(func_response),
                },
            ])
            func_outputs.append(str(func_response))
        except Exception as e:
            print(f"[í•¨ìˆ˜ ì‹¤í–‰ ì˜¤ë¥˜] {func_name}: {e}")

    has_funcs = len(func_outputs) > 0

    # 4-1) í•™ì‹/ì‹ë‹¨ ì§ˆì˜ ë³´ê°• í˜¸ì¶œ (LLM ëˆ„ë½ ëŒ€ë¹„ + ê²°ê³¼ ìš”ì•½ system ì£¼ì…)
    lowered = user_input.message.lower()
    cafeteria_keywords = any(k in lowered for k in ["í•™ì‹", "ì‹ë‹¨", "ì ì‹¬", "ì €ë…", "ë©”ë‰´", "ì¡°ì‹", "ì„ì‹", "ì•„ì¹¨", "ì˜¤ëŠ˜ ë©”ë‰´", "ë°¥ ë­"])
    already_called_cafeteria = any(m.get("name") == "get_halla_cafeteria_menu" for m in func_msgs if m.get("type") == "function_call")


    if cafeteria_keywords and not already_called_cafeteria:
        try:
            print("[DEBUG] Cafeteria fallback engaged (missing function call)")
            # ë¼ë‹ˆê°€ ëª…ì‹œë˜ë©´ í•´ë‹¹ ë¼ë‹ˆ, ì•„ë‹ˆë©´ ì „ì²´ ë°˜í™˜í•˜ë„ë¡ None í—ˆìš©
            meal_pref = None
            if any(x in lowered for x in ["ì¡°ì‹", "ì•„ì¹¨"]):
                meal_pref = "ì¡°ì‹"
            elif any(x in lowered for x in ["ì„ì‹", "ì €ë…"]):
                meal_pref = "ì„ì‹"
            elif "ì ì‹¬" in lowered or "ì¤‘ì‹" in lowered:
                meal_pref = "ì¤‘ì‹"
            date_pref = "ì˜¤ëŠ˜"
            if "ë‚´ì¼" in lowered:
                date_pref = "ë‚´ì¼"
            else:
                import re as _re
                m = _re.search(r"(\d{4}[./-]\d{1,2}[./-]\d{1,2})", user_input.message)
                if m:
                    date_pref = m.group(1)
            caf_args = {"date": date_pref, "meal": meal_pref}
            get_cafeteria_fn = func_calling.available_functions.get("get_halla_cafeteria_menu")
            if not get_cafeteria_fn:
                raise RuntimeError("get_halla_cafeteria_menu not registered")
            caf_out = get_cafeteria_fn(**caf_args)
            call_id = "cafeteria_auto"
            func_msgs.extend([
                {"type": "function_call", "call_id": call_id, "name": "get_halla_cafeteria_menu", "arguments": json.dumps(caf_args, ensure_ascii=False)},
                {"type": "function_call_output", "call_id": call_id, "output": str(caf_out)},
            ])
            func_outputs.append(str(caf_out))
            has_funcs = True
            # ê°„ë‹¨ ìš”ì•½ ë¸”ë¡ (LLM í˜¸ì¶œ ì—†ì´ ê·œì¹™ ê¸°ë°˜ ì¶•ì•½)
            first_lines = "\n".join([ln for ln in str(caf_out).splitlines()[:8]])
            cafeteria_summary_block = f"<í•™ì‹ìš”ì•½>ìš”ì²­ì¼ì={date_pref}, ì‹ì‚¬={meal_pref or 'ì „ì²´'}\n{first_lines}</í•™ì‹ìš”ì•½>"
        except Exception as e:
            print(f"[ë³´ê°• í˜¸ì¶œ ì‹¤íŒ¨] get_halla_cafeteria_menu: {e}")

    # 5) ìµœì¢… ìŠ¤íŠ¸ë¦¬ë°ì— ì‚¬ìš©í•  ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    base_context = chatbot.to_openai_context(chatbot.context[:])
    temp_context = base_context[:]

    # ì´í›„ í•˜ë‚˜ì˜ system ë©”ì‹œì§€ë¡œ í•©ì¹  ì„¹ì…˜ì„ ìˆ˜ì§‘
    sections: list[str] = []
    query_guidance = (
        f"ì´ê²ƒì€ ì‚¬ìš©ì ì¿¼ë¦¬ì…ë‹ˆë‹¤: {user_input.message}\n"
        "ë‹¤ìŒ ì •ë³´ë¥¼ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ëŒ€ë‹µì— ë§ê²Œ í†µí•©í•´ ì „ë‹¬í•˜ì„¸ìš”.\n"
        "- í•¨ìˆ˜í˜¸ì¶œ ê²°ê³¼: ìˆìœ¼ë©´ ë°˜ì˜\n- ê¸°ì–µê²€ìƒ‰ ê²°ê³¼: ìˆìœ¼ë©´ ë°˜ì˜ / í•¨ìˆ˜ í˜¸ì¶œ ì¡´ì¬ ìì²´ëŠ” ì–¸ê¸‰ ê¸ˆì§€"
    )
    sections.append("[ì‚¬ìš©ìì¿¼ë¦¬ì§€ì¹¨]\n" + query_guidance)
    sections.append("[ì¼ë°˜ì§€ì¹¨]\n" + chatbot.instruction)

    if has_rag:
        # 5-1) ê¸°ì–µê²€ìƒ‰ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ë„£ì§€ ì•Šê³ , ë¨¼ì € LLMìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ê²Œ ê°€ê³µ/ìš”ì•½
        def _sanitize_text(txt: str) -> str:
            # ì œì–´ë¬¸ì ì œê±° ë° íƒœê·¸ ì¶©ëŒ ë°©ì§€
            if not isinstance(txt, str):
                txt = str(txt)
            # ê°„ë‹¨ ì œì–´ë¬¸ì í•„í„°ë§ (LF, TAB ì œì™¸)
            txt = ''.join(ch for ch in txt if ch in ('\n', '\t') or (ord(ch) >= 32 and ch != 127))
            # íƒœê·¸ ì¡°ê¸° ì¢…ë£Œ ë°©ì§€
            txt = txt.replace("</ê¸°ì–µê²€ìƒ‰>", "[/ê¸°ì–µê²€ìƒ‰]")
            # ê³¼ë„í•œ ê¸¸ì´ í´ë¨í”„ (í•„ìš”ì‹œ ì¡°ì •)
            # í‘œ/ì£¼ì„ ë‹¨ìœ„ì˜ ë„“ì€ ë§¥ë½ì„ ì¶©ë¶„íˆ ë‹´ê¸° ìœ„í•´ ìƒí•œì„ í™•ëŒ€
            max_len = 30000
            return txt[:max_len]

        sanitized_rag = _sanitize_text(rag_ctx)

        condense_prompt = [
            {
                "role": "system",
                "content": (
                    f"""
ë‹¹ì‹ ì€ ê¸´ ê·œì •/ì„¸ì¹™ ë¬¸ì„œ ë¬¶ìŒì—ì„œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ëœ ë¶€ë¶„ì„ "ë„“ì€ ë§¥ë½"ìœ¼ë¡œ ì¶”ì¶œÂ·í‘œì‹œí•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ê·œì¹™(ë„“ì€ ë§¥ë½ í¬í•¨):
1) ì›ë¬¸ ì „ì²´ëŠ” <ê¸°ì–µê²€ìƒ‰> íƒœê·¸ ì•ˆì— ìˆìŠµë‹ˆë‹¤.
2) ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ëœ ê·¼ê±°ëŠ” <ë°˜ì˜>...</ë°˜ì˜> íƒœê·¸ ì•ˆì— ë‹´ë˜, ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”.
   - í‘œ/ëª©ë¡/ë²ˆí˜¸ ì¡°í•­ì€ í•´ë‹¹ í•­ëª©ì˜ ë¨¸ë¦¬ê¸€(ì œëª©/í—¤ë”)ê³¼ ì¸ì ‘ í–‰Â·í•­ê¹Œì§€ í•¨ê»˜ í¬í•¨(ìµœì†Œ Â±5~10ì¤„ ë§¥ë½).
   - "ì£¼)" í˜•íƒœì˜ ì£¼ì„/ë¹„ê³ ê°€ ë¶™ì€ ê²½ìš° í•´ë‹¹ ì£¼ì„ ì „ë¶€ í¬í•¨.
   - í•™ì Â·ê³¼ëª©Â·ë°°ë¶„ì˜ì—­Â·íŠ¸ë™ê³¼ ê°™ì€ ìˆ«ì/í•­ëª©ì€ í‘œì˜ ì—´ ë¨¸ë¦¬ë§ê³¼ ê°™ì´ í¬í•¨(í—¤ë”+í–‰ ì„¸íŠ¸).
3) ì‚¬ìš©ìê°€ íŠ¹ì • ë²ˆí˜¸(ì˜ˆ: 1ë²ˆ, 2ë²ˆ)ë¥¼ ì–¸ê¸‰í–ˆì§€ë§Œ ëª¨í˜¸í•  ê²½ìš°, í›„ë³´ ë²ˆí˜¸ 2~3ê°œë¥¼ ëª¨ë‘ í¬í•¨í•˜ë˜ ê° ë¸”ë¡ ì•ì— [í›„ë³´] í‘œê¸°.
4) ê´€ë ¨ ê·¼ê±°ê°€ ì¶©ë¶„ì¹˜ ì•Šë‹¤ê³  íŒë‹¨ë˜ë©´, ìƒìœ„ ë‹¨ë½(ì¡°/í•­/í‘œ ì œëª©) ë‹¨ìœ„ê¹Œì§€ í™•ì¥í•˜ì—¬ ìµœì†Œ 15ì¤„ ì´ìƒì„ ë‹´ê³ , ì§€ë‚˜ì¹œ ìš”ì•½ì„ í”¼í•˜ì„¸ìš”.
5) ì›ë¬¸ êµ¬ì¡°(ì¡°/í•­/í˜¸/í‘œ ì œëª©)ëŠ” ìœ ì§€í•˜ê³  ì„ì˜ ì¬ì‘ì„± ê¸ˆì§€. ë°˜ë“œì‹œ ì›ë¬¸ì„ ê±°ì˜ ê·¸ëŒ€ë¡œ ì¸ìš©í•˜ì„¸ìš”.
6) ì›ë¬¸ ë°– ì¶”ë¡ /ì°½ì‘ ê¸ˆì§€.

ì‚¬ìš©ì ì§ˆë¬¸: {user_input.message}
<ê¸°ì–µê²€ìƒ‰>{sanitized_rag}</ê¸°ì–µê²€ìƒ‰>
"""
                ),
            }
        ]

        # ë””ë²„ê·¸: condense_promptì™€ rag_ctx ì¶œë ¥
        print("==== [DEBUG] condense_prompt ====")
        for item in condense_prompt:
            print(item)
        print("==== [DEBUG] rag_ctx ====")
        print(rag_ctx)

        try:
            condensed = client.responses.create(
                model=model.advanced,
                input=condense_prompt,
                text={"format": {"type": "text"}},
            ).output_text.strip()
            print("==== [DEBUG] condensed ====")
            print(condensed)
            # ê²°ê³¼ê°€ ì§€ë‚˜ì¹˜ê²Œ ì§§ìœ¼ë©´(ì¤„ ìˆ˜<15 ë˜ëŠ” ê¸¸ì´<1000ì) ë„“ì€ ë§¥ë½ ì¬ì‹œë„
            if (condensed.count("\n") < 15) or (len(condensed) < 1000):
                print("[DEBUG] condensed too short -> retry with broader extraction")
                broader_prompt = [
                    {
                        "role": "system",
                        "content": (
                            f"""
ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í‘œ/ë²ˆí˜¸ì¡°í•­/ì£¼ì„ì˜ ì „ì²´ ë§¥ë½ì„ ë„“ê²Œ í¬í•¨í•´ ì¶”ì¶œí•©ë‹ˆë‹¤.
ë°˜ë“œì‹œ ë‹¤ìŒì„ ì§€í‚¤ì„¸ìš”:
- <ë°˜ì˜>...</ë°˜ì˜> ì•ˆì— í—¤ë”(í‘œ ì œëª©/ì—´ ë¨¸ë¦¬ë§) + ê´€ë ¨ í–‰/í•­ ì „ë¶€ì™€ í•´ë‹¹ ì£¼ì„(ì£¼)ê¹Œì§€ í¬í•¨.
- ìµœì†Œ 25ì¤„ ì´ìƒ, ê°€ëŠ¥í•˜ë©´ ê´€ë ¨ ë¸”ë¡ì„ í†µì§¸ë¡œ í¬í•¨(ë¶ˆí•„ìš”í•œ ìš”ì•½ ê¸ˆì§€).
- ëª¨í˜¸í•˜ë©´ í›„ë³´ ë¸”ë¡ 2~3ê°œë¥¼ [í›„ë³´]ë¡œ ë‚˜ëˆ„ì–´ ëª¨ë‘ í¬í•¨.
ì›ë¬¸: <ê¸°ì–µê²€ìƒ‰>{sanitized_rag}</ê¸°ì–µê²€ìƒ‰>
ì§ˆë¬¸: {user_input.message}
"""
                        ),
                    }
                ]
                try:
                    condensed2 = client.responses.create(
                        model=model.advanced,
                        input=broader_prompt,
                        text={"format": {"type": "text"}},
                    ).output_text.strip()
                    print("==== [DEBUG] condensed(broader) ====")
                    print(condensed2)
                    # ë” ê¸¸ê³  í’ë¶€í•˜ë©´ êµì²´
                    if (condensed2.count("\n") >= condensed.count("\n")) and (len(condensed2) > len(condensed)):
                        condensed = condensed2
                except Exception as _e2:
                    print(f"[DEBUG] broader extraction failed: {_e2}")
        except Exception as _e:
            # ìš”ì•½ ì‹¤íŒ¨ ì‹œ ì›ë¬¸ì„ ì§§ê²Œ ì˜ë¼ ì‚¬ìš©
            print(f"[DEBUG] ë¬¸ì„œ ìš”ì•½ ì‹¤íŒ¨: {_e}")
            condensed = sanitized_rag[:6000]

        rag_guidance = (
            "ê¸°ì–µê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤. <ë°˜ì˜> </ë°˜ì˜> íƒœê·¸ ë‚´ë¶€ ë‚´ìš©ì„ ë³´ê³  ì‚¬ìš©ìì˜ ì›í•˜ëŠ” ì¿¼ë¦¬ì— ë§ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”. "
            "<ê¸°ì–µê²€ìƒ‰></ê¸°ì–µê²€ìƒ‰> íƒœê·¸ëŠ” ì°¸ì¡°ìš©ì´ë©° íƒœê·¸ ë°– ì„ì˜ ì°½ì‘ ê¸ˆì§€"
        )
        sections.append("[ê¸°ì–µê²€ìƒ‰ì§€ì¹¨]\n" + rag_guidance)
        sections.append("[ê¸°ì–µê²€ìƒ‰]\n<ê¸°ì–µê²€ìƒ‰>\n" + condensed + "\n</ê¸°ì–µê²€ìƒ‰>")

    web_status = None  # 'ok' | 'empty-or-error' | 'not-run'
    if has_funcs:
        # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ ë¬¸ìì—´ êµ¬ì„± (ì›¹ê²€ìƒ‰ ê²°ê³¼ëŠ” ë¶„ë¦¬ ìˆ˜ì§‘)
        formatted_blocks_other = []
        formatted_blocks_web = []
        web_outputs: list[str] = []
        # func_msgsëŠ” [call, output, call, output, ...] êµ¬ì¡°ì´ë¯€ë¡œ 2ê°œì”© ë¬¶ì–´ ì²˜ë¦¬
        try:
            for i in range(0, len(func_msgs), 2):
                call = func_msgs[i]
                if i + 1 < len(func_msgs):
                    output = func_msgs[i + 1]
                else:
                    output = {"output": "(ì¶œë ¥ ëˆ„ë½)"}
                if call.get("type") != "function_call":
                    continue
                name = call.get("name")
                args = call.get("arguments")
                out_text = output.get("output", "") if isinstance(output, dict) else str(output)
                # ë„ˆë¬´ ê¸´ ì¶œë ¥ì€ ì˜ë¼ëƒ„ (ì•ˆì „)
                max_len = 4000
                if len(out_text) > max_len:
                    out_text = out_text[:max_len] + "...<truncated>"
                # ì›¹ê²€ìƒ‰ ìƒíƒœ ìˆ˜ì§‘
                if name == "search_internet":
                    web_outputs.append(out_text)
                    formatted_blocks_web.append(f"<function name='{name}' args='{args}'>\n{out_text}\n</function>")
                else:
                    formatted_blocks_other.append(f"<function name='{name}' args='{args}'>\n{out_text}\n</function>")
        except Exception as _fmt_e:
            print(f"[DEBUG] function result formatting error: {_fmt_e}")
        web_functions_block = "\n".join(formatted_blocks_web) if formatted_blocks_web else ""
        other_functions_block = "\n".join(formatted_blocks_other) if formatted_blocks_other else ""

        # í•™ì‹ ë³´ê°• ìš”ì•½ ë¸”ë¡ì´ ìˆë‹¤ë©´ í¬í•¨
        try:
            if 'cafeteria_summary_block' in locals() and cafeteria_summary_block:
                functions_block += f"\n{cafeteria_summary_block}"
        except Exception:
            pass

        # ì›¹ê²€ìƒ‰ ìƒíƒœ íŒë‹¨
        if not web_outputs:
            web_status = "not-run"
        else:
            # í•˜ë‚˜ë¼ë„ ì˜ë¯¸ ìˆëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ok, ëª¨ë‘ ì˜¤ë¥˜/ë¹„ì–´ìˆìŒì´ë©´ empty-or-error
            def _is_error_or_empty(txt: str) -> bool:
                t = (txt or "").strip()
                if not t:
                    return True
                err_keywords = ["ğŸš¨", "âŒ", "ì˜¤ë¥˜", "error", "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜", "no result", "did_call=False"]
                return any(k.lower() in t.lower() for k in err_keywords)
            all_bad = all(_is_error_or_empty(t) for t in web_outputs)
            web_status = "empty-or-error" if all_bad else "ok"

        # ì§€ì¹¨: ì›¹ê²€ìƒ‰ ê²°ê³¼ëŠ” ë”°ë¡œ í‘œê¸°í•˜ê³ , ìš°íšŒ/ë¬¸ì˜ ì•ˆë‚´ë§Œ ìˆëŠ” ê²½ìš° ì°¸ê³ ë§Œ í•˜ë„ë¡ ëª…ì‹œ
        web_guidance = (
            "ë‹¤ìŒì€ ì¸í„°ë„· ê²€ìƒ‰ê²°ê³¼ì…ë‹ˆë‹¤. ê³µì‹ ê·¼ê±°ê°€ ì•„ë‹ˆë¯€ë¡œ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì„¸ìš”. "
            "ê²€ìƒ‰ì´ ì•ˆë˜ì–´ ìš°íšŒ/ë¬¸ì˜ ì•ˆë‚´ë§Œ ìˆì„ ê²½ìš°, ë¬´ì‹œí•˜ê³  ì´ ë‚´ìš©ì€'ì°¸ì¡°ë§Œ' í•˜ì„¸ìš”. ë°˜ë“œì‹œ ê¸°ì–µê²€ìƒ‰ ê·¼ê±°ë¥¼ ìš°ì„  ë°˜ì˜í•˜ì„¸ìš”. ì°¸ì¡°ë€ ì•ˆë‚´ ì „í™”ë²ˆí˜¸ ì‚¬ì´íŠ¸ë§Œì„ ë°˜ì˜í•˜ëŠ”ê²ƒì„ ë§í•©ë‹ˆë‹¤ "
        )
        sections.append("[ì›¹ê²€ìƒ‰ì§€ì¹¨]\n" + web_guidance)
        if web_functions_block:
            sections.append("[ì¸í„°ë„· ê²€ìƒ‰ê²°ê³¼]\n<ì¸í„°ë„·ê²€ìƒ‰>\n" + web_functions_block + "\n</ì¸í„°ë„·ê²€ìƒ‰>")

        func_guidance = (
            "ë‹¤ìŒì€ í•¨ìˆ˜(ê²€ìƒ‰/ë©”ë‰´ ë“±) í˜¸ì¶œ ê²°ê³¼ì…ë‹ˆë‹¤. <í•¨ìˆ˜ê²°ê³¼> íƒœê·¸ ë‚´ë¶€ ë‚´ìš©ì€ ì°¸ê³ ìš©ì´ë©°, ë°˜ë“œì‹œ ì•„ë˜ ê¸°ì–µê²€ìƒ‰(<ê¸°ì–µê²€ìƒ‰>) ê·¼ê±°ë¥¼ ìš°ì„  ë‹µë³€ì— ë°˜ì˜í•˜ì„¸ìš”. "
            "'í•¨ìˆ˜ í˜¸ì¶œ'ì´ë¼ëŠ” í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ê±°ì§“ ì •ë³´ ìƒì„± ê¸ˆì§€."
        )
        sections.append("[í•¨ìˆ˜ê²°ê³¼ì§€ì¹¨]\n" + func_guidance)
        if other_functions_block:
            sections.append("[í•¨ìˆ˜ê²°ê³¼]\n<í•¨ìˆ˜ê²°ê³¼>\n" + other_functions_block + "\n</í•¨ìˆ˜ê²°ê³¼>")
        # ì›¹ê²€ìƒ‰ ìƒíƒœ í‘œì‹œ (ìˆì„ ë•Œë§Œ)
        if web_status and web_status != "not-run":
            status_kr = {
                "ok": "ì •ìƒ",
                "empty-or-error": "ê²°ê³¼ì—†ìŒ/ì˜¤ë¥˜",
                "not-run": "ì‹¤í–‰ì•ˆí•¨",
            }[web_status]
            sections.append("[ì›¹ê²€ìƒ‰ìƒíƒœ]\n" + status_kr)

        # ì›¹ê²€ìƒ‰ì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨í–ˆì„ ë•Œì˜ ë‹µë³€ ì§€ì¹¨ (ë¶ˆí•„ìš”í•œ ë§ ê¸ˆì§€)
        if web_status in ("empty-or-error", "not-run"):
            if has_rag:
                sections.append(
                    "[ì›¹ê²€ìƒ‰ê²°ê³¼ì—†ìŒì§€ì¹¨]\nì¸í„°ë„· ê²€ìƒ‰ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤. ê³µì‹ ê·œì •ì€ ì•„ë˜ ê¸°ì–µê²€ìƒ‰(<ê¸°ì–µê²€ìƒ‰>) ê·¼ê±°ë¥¼ ë°˜ë“œì‹œ ìš°ì„  í™•ì¸í•˜ì„¸ìš”. ê²€ìƒ‰ì´ ë˜ì§€ ì•Šê±°ë‚˜ ë¬¸ì˜ ì•ˆë‚´ë§Œ ìˆì„ ê²½ìš°, í•´ë‹¹ ë‚´ìš©ì€ ì°¸ê³ ë§Œ í•˜ì‹œê³  ë°˜ë“œì‹œ ì•„ë˜ ê·œì • ê·¼ê±°ë¥¼ ë‹µë³€ì— ë°˜ì˜í•˜ì„¸ìš”."
                )
            else:
                sections.append(
                    "[ì›¹ê²€ìƒ‰ê²°ê³¼ì—†ìŒì§€ì¹¨]\nì›¹ê²€ìƒ‰ ê²°ê³¼ëŠ” ì—†ì—ˆìŠµë‹ˆë‹¤. ê´€ë ¨ ê·¼ê±°ë¥¼ ì°¾ì§€ ëª»í–ˆìŒì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨íˆ ì•Œë¦¬ê³ , í•„ìš”í•œ ì¶”ê°€ ì •ë³´ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì²­í•˜ì„¸ìš”."
                )
       

    if has_rag and has_funcs:
        # ì›¹ê²€ìƒ‰ì´ ë¹„ì–´ë„(ê²°ê³¼ì—†ìŒ/ì˜¤ë¥˜) ê¸°ì–µê²€ìƒ‰ì´ ìˆìœ¼ë©´ 'ì •ë³´ ì—†ìŒ'ì´ë¼ê³  ê²°ë¡ ë‚´ë¦¬ì§€ ë§ë¼ëŠ” ê·œì¹™ ì¶”ê°€
        extra = " ì›¹ê²€ìƒ‰ì´ ê²°ê³¼ì—†ìŒ/ì˜¤ë¥˜ì—¬ë„ ê¸°ì–µê²€ìƒ‰ì´ ì¡´ì¬í•˜ë©´ 'ì •ë³´ ì—†ìŒ'ì´ë¼ê³  í•˜ì§€ ë§ê³  ê¸°ì–µê²€ìƒ‰ ê·¼ê±°ë¡œ ë‹µí•  ê²ƒ."
        if web_status == "empty-or-error":
            extra_note = extra
        else:
            extra_note = ""
        merge_instruction = (
            "ìœ„ ê¸°ì–µê²€ìƒ‰ ê·¼ê±°(<ê¸°ì–µê²€ìƒ‰>)ì™€ ì¸í„°ë„· ê²€ìƒ‰ê²°ê³¼(<ì¸í„°ë„·ê²€ìƒ‰>), ê¸°íƒ€ í•¨ìˆ˜ê²°ê³¼(<í•¨ìˆ˜ê²°ê³¼>)ë¥¼ ëŒ€ì¡°í•˜ì—¬ ëª¨ìˆœ ì—†ì´ ë‹µí•˜ì„¸ìš”. "
            "í•µì‹¬ ë‹µ ë¨¼ì € ì œì‹œí•˜ê³ , í•„ìš”í•œ ê·¼ê±°ë§Œ ì¶•ì•½ ì¸ìš©. ì¸í„°ë„· ê²€ìƒ‰ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ë©°, ìš°íšŒ/ë¬¸ì˜ ì•ˆë‚´ë§Œ ìˆì„ ê²½ìš° 'ì°¸ì¡°ë§Œ' í•˜ê³  -ì°¸ì¡°ë€ ì•ˆë‚´ ì „í™”ë²ˆí˜¸ ì‚¬ì´íŠ¸ë§Œì„ ë°˜ì˜í•˜ëŠ”ê²ƒì„ ë§í•©ë‹ˆë‹¤   "
            "ë°˜ë“œì‹œ ê¸°ì–µê²€ìƒ‰ ê·¼ê±°ë¥¼ ìš°ì„  ë°˜ì˜í•˜ì„¸ìš”. ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ê·¸ ì‚¬ì‹¤ì„ ëª…ì‹œ." + extra_note
        )
        sections.append("[í†µí•©ì§€ì¹¨]\n" + merge_instruction)

    # ë‹¨ì¼ system ë©”ì‹œì§€ë¡œ ë³‘í•© ì¶”ê°€
    temp_context.append({
        "role": "system",
        "content": "\n\n".join(sections)
    })

    # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì›ë³¸ ì»¨í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•´ ì¼ë°˜ ì‘ë‹µ
    context_to_stream = temp_context if (has_rag or has_funcs) else base_context

    # 6) ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ë° ìµœì¢… ë¬¸ë§¥ ì €ì¥
    async def generate_with_tool():
        completed_text = ""
        try:
            stream = client.responses.create(
                model=chatbot.model,
                input=context_to_stream,
                top_p=1,
                stream=True,
                text={"format": {"type": "text"}},
            )

            loading = True
            for event in stream:
                match event.type:
                    # case "response.created":
                    #     loading = True
                    #     yield "â³ GPTê°€ ì‘ë‹µì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."
                    #     await asyncio.sleep(0)
                    case "response.output_text.delta":
                        # if loading:
                        #     yield "\n[ï¿½ ì‘ë‹µ ì‹œì‘ë¨ â†“]"
                        #     loading = False
                        yield f"{event.delta}"
                        await asyncio.sleep(0)
                    # case "response.in_progress":
                    #     yield "\n[ğŸŒ€ ì‘ë‹µ ìƒì„± ì¤‘...]\n"
                    case "response.output_item.done":
                        item = event.item
                        if item.type == "message" and item.role == "assistant":
                            for part in item.content:
                                if getattr(part, "type", None) == "output_text":
                                    completed_text = part.text
                    # case "response.completed":
                    #     yield "\n"
                    # case "response.failed":
                    #     yield "âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨"
                    # case "error":
                    #     yield "âš ï¸ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì—ëŸ¬ ë°œìƒ!"
                    # case _:
                    #     yield f"\n[ğŸ“¬ ê¸°íƒ€ ì´ë²¤íŠ¸ ê°ì§€: {event.type}]"
        except Exception as e:
            yield f"\nStream Error: {str(e)}"
        finally:
            if completed_text:
                chatbot.add_response_stream(completed_text)
            print(context_to_stream)

    return StreamingResponse(generate_with_tool(), media_type="text/plain")