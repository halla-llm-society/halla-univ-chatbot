import json
import requests
import httpx
from pprint import pprint
import re
import time
from datetime import datetime, timedelta
from typing import Optional
from bs4 import BeautifulSoup
import os
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv
from dataclasses import dataclass

# LLM Manager import
try:
    from app.ai.llm import get_provider
except ImportError:
    # ìƒëŒ€ ê²½ë¡œë¡œ ì‹œë„
    from ..llm import get_provider

# ShuttleBus Service import
try:
    from app.ai.functions.shuttle_bus_service import ShuttleBusService
except ImportError:
    from .shuttle_bus_service import ShuttleBusService

# ìˆœí™˜ ì°¸ì¡° ë°©ì§€: config ëŒ€ì‹  ì§ì ‘ ìƒì„±
_BASE_DIR = Path(__file__).resolve().parent.parent.parent  # app/
_DOTENV_PATH = _BASE_DIR / "apikey.env"
load_dotenv(_DOTENV_PATH)

@dataclass(frozen=True)
class Model: 
    basic: str = "gpt-3.5-turbo-1106"
    advanced: str = "gpt-4.1"
    o3_mini: str = "o3-mini"
    o1: str = "o1"

model = Model()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key, max_retries=1)

def makeup_response(message, finish_reason="ERROR"):
    '''api ì‘ë‹µí˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì„œ
       ê°œë°œìê°€ ì„ì˜ë¡œ ìƒì„±í•œ ë©”ì„¸ì§€ë¥¼
       ê¸°ì¡´ ì¶œë ¥ í•¨ìˆ˜ë¡œ ì¶œë ¥í•˜ëŠ” ìš©ë„ì¸ í•¨ìˆ˜'''
    return {
        "choices": [
            {
                "finish_reason": finish_reason,
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": message
                }                   
            }
        ],
        "usage": {"total_tokens": 0},
    }
    
tools = [
        
            {
            "type": "function",
            "name": "search_internet",
            "description": """ì¸í„°ë„·ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

            âš ï¸ ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°:
            - ìµœì‹  ê³µì§€ì‚¬í•­, ë‰´ìŠ¤, ì´ë²¤íŠ¸ ì •ë³´
            - í•œë¼ëŒ€í•™êµ ì›¹ì‚¬ì´íŠ¸ì˜ ìµœì‹  ì •ë³´
            - ì¼ë°˜ì ì¸ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°

            âŒ ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•˜ëŠ” ê²½ìš°:
            - í†µí•™ë²„ìŠ¤, ì…”í‹€ë²„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ â†’ get_shuttle_bus_info ì‚¬ìš©
            - í•™ì‹, ì‹ë‹¨ ê´€ë ¨ ì§ˆë¬¸ â†’ get_halla_cafeteria_menu ì‚¬ìš©
            - í•™ì‚¬ê·œì • ê´€ë ¨ ì§ˆë¬¸ â†’ RAG ì‹œìŠ¤í…œ ì‚¬ìš© (ìë™ ì²˜ë¦¬)

            í†µí•™ë²„ìŠ¤ ì‹œê°„í‘œ, íƒ‘ìŠ¹ ìœ„ì¹˜, ì˜ˆì•½ ë°©ë²• ë“±ì€ ë°˜ë“œì‹œ get_shuttle_bus_info í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.""",
            "parameters": {
                "type": "object",
                "required": [
                "user_input"
                ],
                "properties": {
                "user_input": {
                    "type": "string",
                    "description": "User's search query input(conversation context will be automatically added)"
                }
                },
                "additionalProperties": False
            }
            },
            {
            "type": "function",
            "name": "get_halla_cafeteria_menu",
            "description": "ì›ì£¼ í•œë¼ëŒ€í•™êµ í•™ìƒì‹ë‹¹ê³¼ êµì§ì›ì‹ë‹¹ì˜ ë©”ë‰´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ì£¼ê°„ ì‹ë‹¨ í˜ì´ì§€ì—ì„œ íŠ¹ì • ë‚ ì§œ/ë¼ë‹ˆì˜ ë©”ë‰´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. í•™ìƒì‹ë‹¹(/kr/211/)ê³¼ êµì§ì›ì‹ë‹¹(/kr/212/) ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "required": ["date"],
                "properties": {
                    "date": {
                        "type": "string",
                        "description": """ì¡°íšŒí•  ë‚ ì§œë¥¼ ì •ê·œí™”í•˜ì—¬ ì „ë‹¬í•©ë‹ˆë‹¤.
í—ˆìš© í˜•ì‹:
- ìƒëŒ€ ë‚ ì§œ: "ì˜¤ëŠ˜", "ë‚´ì¼", "ëª¨ë ˆ", "ì–´ì œ"
- ì ˆëŒ€ ë‚ ì§œ: YYYY-MM-DD í˜•ì‹ (ì˜ˆ: "2025-11-18")
- ì˜¤íƒ€ ì²˜ë¦¬: "ì•¼ëª¨ë ˆ" â†’ "ëª¨ë ˆ"ë¡œ ìë™ ë³€í™˜
- ìì—°ì–´: "ì´í‹€ í›„" â†’ "ëª¨ë ˆ", "ë‹¤ìŒì£¼ ì›”ìš”ì¼" â†’ ë‚ ì§œ ê³„ì‚°
ê¸°ë³¸ê°’: "ì˜¤ëŠ˜" """,
                    },
                    "meal": {
                        "type": "string",
                        "enum": ["ì¡°ì‹", "ì¤‘ì‹", "ì„ì‹"],
                        "description": "ì¡°íšŒí•  ë¼ë‹ˆ. ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ë¼ë‹ˆë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.",
                    },
                    "cafeteria_type": {
                        "type": "string",
                        "enum": ["í•™ìƒ", "êµì§ì›"],
                        "description": "ì‹ë‹¹ ì¢…ë¥˜. 'í•™ìƒ' ë˜ëŠ” 'êµì§ì›'. ê¸°ë³¸ê°’ì€ 'í•™ìƒ'ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ 'êµì§ì›', 'êµìˆ˜', 'ì§ì›' ë“±ì˜ í‚¤ì›Œë“œë¥¼ ì–¸ê¸‰í•˜ë©´ 'êµì§ì›'ì„ ì„ íƒí•˜ì„¸ìš”.",
                    }
                },
                "additionalProperties": False
            }
            },
            {
            "type": "function",
            "name": "get_halla_academic_calendar",
            "description": "í•œë¼ëŒ€í•™êµ í•™ì‚¬ì¼ì •ì„ ì¡°íšŒí•©ë‹ˆë‹¤. íŠ¹ì • ì›”ì˜ í•™ì‚¬ ì¼ì •(ê°œê°•, ì¢…ê°•, ì‹œí—˜, ë°©í•™ ë“±)ì„ ì œê³µí•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "required": [],
                "properties": {
                    "month": {
                        "type": "string",
                        "description": """ì¡°íšŒí•  ì›”ì„ ì§€ì •í•©ë‹ˆë‹¤.
í—ˆìš© í˜•ì‹:
- ìƒëŒ€ ì›”: "ì´ë²ˆë‹¬", "ë‹¤ìŒë‹¬", "ì§€ë‚œë‹¬"
- ì ˆëŒ€ ì›”: "3ì›”", "12ì›”" (ì˜¬í•´ ê¸°ì¤€)
- YYYY-MM í˜•ì‹: "2025-03"
- YYYYë…„ MMì›”: "2025ë…„ 3ì›”"
- ìˆ«ì: "3", "12" (1~12ëŠ” ì›”ë¡œ í•´ì„)
ê¸°ë³¸ê°’: í˜„ì¬ ì›”""",
                    }
                },
                "additionalProperties": False
            }
            },
            {
            "type": "function",
            "name": "get_shuttle_bus_info",
            "description": """í•œë¼ëŒ€í•™êµ í†µí•™ë²„ìŠ¤(ì…”í‹€ë²„ìŠ¤) ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì „ìš© í•¨ìˆ˜ì…ë‹ˆë‹¤.

            âš ï¸ ì´ í•¨ìˆ˜ë¥¼ ë°˜ë“œì‹œ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°:
            - 'í†µí•™ë²„ìŠ¤', 'ì…”í‹€ë²„ìŠ¤', 'ìŠ¤ì¿¨ë²„ìŠ¤' ê´€ë ¨ ì§ˆë¬¸
            - 'ë“±êµ', 'í•˜êµ' ì‹œê°„ ë¬¸ì˜
            - 'ì›ì£¼ì—­', 'ë§Œì¢…ì—­', 'ì²­ì†”', 'ì‹œì™¸ë²„ìŠ¤í„°ë¯¸ë„' ë“± ì›ì£¼ ì‹œë‚´ ì¶œë°œì§€
            - 'ì„œìš¸', 'ìˆ˜ì›', 'ì—¬ì£¼', 'ì ì‹¤', 'ê°•ë³€', 'ë…¸ì›' ë“± ì‹œì™¸ ì¶œë°œì§€
            - ë²„ìŠ¤ íƒ‘ìŠ¹ ìœ„ì¹˜, ì‹œê°„í‘œ, ë…¸ì„ , ì˜ˆì•½ ë°©ë²•, ìš”ê¸ˆ ì§ˆë¬¸

            âš ï¸ í†µí•™ë²„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ì€ ì¸í„°ë„· ê²€ìƒ‰ì´ ì•„ë‹Œ ì´ í•¨ìˆ˜ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.

            ì§€ì› ì •ë³´:
            - ì‹œë‚´ë²„ìŠ¤: ë§Œì¢…ì—­, ëŒ€ëª…ì›, ì‹œì™¸ë²„ìŠ¤í„°ë¯¸ë„, ë¬´ì‹¤ë™, ì›ì£¼ì—­, ì²­ì†”ì•„íŒŒíŠ¸, í•œêµ­ê°€ìŠ¤ê³µì‚¬, ì˜¤ì„±ë§ˆì„, ì˜¤í˜ë¼ì›¨ë”©í™€
            - ì‹œì™¸ë²„ìŠ¤: ì„œìš¸(ì ì‹¤,ê°•ë³€,ìƒë´‰,ì²œí˜¸,ë…¸ì›), ìˆ˜ì›/ì—¬ì£¼(ë¼ë§ˆë‹¤í˜¸í…”,ì•„ì£¼ëŒ€,ì˜í†µ,ê¸°í¥,ì—¬ì£¼ì—­)
            - ì´ìš©ì•ˆë‚´: ì˜ˆì•½ë°©ë²•, ì·¨ì†Œë°©ë²•, ìš”ê¸ˆ, ì ë¦½ê¸ˆ""",
            "parameters": {
                "type": "object",
                "required": ["user_query"],
                "properties": {
                    "user_query": {
                        "type": "string",
                        "description": "ì‚¬ìš©ìì˜ í†µí•™ë²„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ ì›ë¬¸. ì˜ˆ: 'ìˆ˜ì› í•˜êµì‹œê°„', 'ì›ì£¼ì—­ ë“±êµ ë²„ìŠ¤', 'ì„œìš¸ í†µí•™ë²„ìŠ¤ ì˜ˆì•½'"
                    }
                },
                "additionalProperties": False
            }
            },



    ]

# --- ê³µì§€ ì¹´í…Œê³ ë¦¬ LLM ë¶„ë¥˜ê¸° ---
async def _classify_notice_category_llm(user_input: str, context_info: str | None = None, token_counter=None) -> str | None:
    """ì‚¬ìš©ì ì…ë ¥ì´ ì–´ë–¤ ê³µì§€ì‚¬í•­ ì¹´í…Œê³ ë¦¬ì¸ì§€ LLMìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ì¹´í…Œê³ ë¦¬ ë¬¸ìì—´ì„ ë°˜í™˜.
    ë°˜í™˜ ê°€ëŠ¥ ê°’: "í•™ì‚¬ê³µì§€", "ë¹„êµê³¼ê³µì§€", "ì¥í•™ê³µì§€", "ì¼ë°˜ê³µì§€", "í•´ë‹¹ì—†ìŒ". ì¸ì‹ ì‹¤íŒ¨ ì‹œ None.
    """
    try:
        allowed = ["í•™ì‚¬ê³µì§€", "ë¹„êµê³¼ê³µì§€", "ì¥í•™ê³µì§€", "ì¼ë°˜ê³µì§€", "í•´ë‹¹ì—†ìŒ"]
        prompt = (
            "ë‹¤ìŒ ì‚¬ìš©ìì˜ ìš”ì²­ì´ í•œë¼ëŒ€í•™êµ 'ê³µì§€' ì¤‘ ì–´ë–¤ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ”ì§€ í•˜ë‚˜ë§Œ ì„ íƒí•´ ë‹µí•˜ì„¸ìš”.\n"
            "ì¹´í…Œê³ ë¦¬: í•™ì‚¬ê³µì§€ | ë¹„êµê³¼ê³µì§€ | ì¥í•™ê³µì§€ | ì¼ë°˜ê³µì§€ | í•´ë‹¹ì—†ìŒ\n"
            "ê·œì¹™:\n"
            "- ì •í™•íˆ ìœ„ì˜ ë‹¨ì–´ ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ë§, ì„¤ëª…, ë”°ì˜´í‘œ ì—†ì´.\n"
            f"ì‚¬ìš©ì ì…ë ¥: {user_input}\n"
            f"ëŒ€í™” ë¬¸ë§¥: {context_info or '(ì—†ìŒ)'}\n\n"
            "ì •ë‹µ:"
        )

        # LLM Managerë¥¼ í†µí•´ Provider ì„ íƒ (êµì²´ ê°€ëŠ¥)
        provider = get_provider("category")
        messages = [{
            "role": "user",
            "content": [{"type": "input_text", "text": prompt}],
        }]
        raw, usage = await provider.simple_completion(messages)
        raw = raw.strip()

        # âœ… API usage ê¸°ë°˜ í† í° ê³„ì‚°
        if token_counter and usage:
            token_counter.update_from_api_usage(
                usage=usage,
                role="category",
                model=provider.get_model_name(),
                category="function"
            )
        
        print("ê³µì§€ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ê¸° ì›ë¬¸:", raw)
        # ì •ê·œí™” ë° ì„ íƒ
        text_norm = raw.replace(" ", "").replace("\n", "")
        for a in allowed:
            if a in text_norm:
                return a
        return None
    except Exception as e:
        print(f"[_classify_notice_category_llm] Error: {e}")
        return None

# --- ê·œì¹™ ê¸°ë°˜ ì‚¬ì´íŠ¸ ì„ í˜¸ ë¼ìš°íŒ… ---
async def _prefer_halla_site_query(user_input: str, context_info: str | None = None, token_counter=None) -> str | None:
    """íŠ¹ì • ìš”êµ¬ì‚¬í•­ì¼ ë•Œ í•œë¼ëŒ€ íŠ¹ì • í˜ì´ì§€ë¥¼ ìš°ì„  íƒìƒ‰í•˜ë„ë¡ ê²€ìƒ‰ì–´ë¥¼ êµ¬ì„±.
    ë§¤ì¹­ë˜ë©´ URLê³¼ site í•„í„°ë¥¼ í¬í•¨í•œ ì¿¼ë¦¬ë¥¼ ë°˜í™˜, ì—†ìœ¼ë©´ None.
    """
    base = (context_info or "")
    text = f"{user_input}\n{base}".lower()

    # ë©”ë‰´/í•™ì‹ ë¼ìš°íŒ…
    menu_keywords = ["í•™ì‹", "ì‹ë‹¨", "ë©”ë‰´", "ì ì‹¬", "ì €ë…", "ì˜¤ëŠ˜ ë©”ë‰´"]
    if any(k in text for k in menu_keywords):
        url = "https://www.halla.ac.kr/kr/211/subview.do"
        return f"site:halla.ac.kr {url} {user_input}"

    # ê³µì§€ ë¼ìš°íŒ…: LLM ë¶„ë¥˜ ê¸°ë°˜ â†’ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°±
    category = await _classify_notice_category_llm(user_input, context_info, token_counter)
    category_to_url = {
        "í•™ì‚¬ê³µì§€": "https://www.halla.ac.kr/kr/242/subview.do",
        "ë¹„êµê³¼ê³µì§€": "https://www.halla.ac.kr/kr/243/subview.do",
        "ì¥í•™ê³µì§€": "https://www.halla.ac.kr/kr/244/subview.do",
        "ì¼ë°˜ê³µì§€": "https://www.halla.ac.kr/kr/241/subview.do",
    }
    if category and category != "í•´ë‹¹ì—†ìŒ":
        url = category_to_url.get(category)
        if url:
            return f"site:halla.ac.kr {url} {user_input}"

    # í´ë°±: ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­
    if "í•™ì‚¬ê³µì§€" in text:
        url = "https://www.halla.ac.kr/kr/242/subview.do"
        return f"{user_input} site:halla.ac.kr {url} "
    if "ë¹„êµê³¼" in text or "ë¹„êµê³¼ê³µì§€" in text:
        url = "https://www.halla.ac.kr/kr/243/subview.do"
        return f"{user_input} site:halla.ac.kr {url}"
    if "ì¥í•™" in text:
        url = "https://www.halla.ac.kr/kr/244/subview.do"
        return f"{user_input} site:halla.ac.kr {url} "
    if "ì¼ë°˜ê³µì§€" in text or "ê³µì§€" in text:
        url = "https://www.halla.ac.kr/kr/241/subview.do"
        return f"{user_input} site:halla.ac.kr {url}"

    # ë¯¸ë§¤ì¹­ ì‹œ ë¼ìš°íŒ… ì—†ìŒ
    return None

async def search_internet(user_input: str, chat_context=None, token_counter=None) -> str:
    start_ts = time.time()
    print(f"[WEB][START] query='{user_input}' chat_ctx={'Y' if chat_context else 'N'}")
    try:
        if chat_context:
            print("[WEB] context available -> trimming recent messages")
            recent_messages = chat_context[-4:]
            context_info = "\n".join([
                f"{m.get('role','unknown')}: {m.get('content','')}" for m in recent_messages if m.get('role') != 'system'
            ])
        else:
            recent_messages = []
            context_info = ""

        preferred = await _prefer_halla_site_query(user_input, context_info if context_info else None, token_counter)
        
        # í˜„ì¬ ë‚ ì§œ ì •ë³´ ì¶”ê°€
        current_date = datetime.now()
        date_str = current_date.strftime("%Yë…„ %mì›” %dì¼")
        year_str = current_date.strftime("%Y")
        
        # ê³µì§€ì‚¬í•­ ê´€ë ¨ ê²€ìƒ‰ì¸ì§€ íŒë‹¨
        is_notice_query = any(keyword in user_input.lower() for keyword in ["ê³µì§€", "notice", "ì•Œë¦¼", "announcement"])
        
        # LLM ì—ì´ì „íŠ¸ë¡œ ê²€ìƒ‰ì–´ ì¬ì‘ì„± (context_info í¬í•¨)
        rewrite_prompt = (
            f"[í˜„ì¬ ë‚ ì§œ] {date_str} ({year_str}ë…„)\n"
            f"[ì‚¬ìš©ì ìš”ì²­] {user_input}\n"
            f"[ëŒ€í™” ë¬¸ë§¥] {context_info or 'ì—†ìŒ'}\n\n"
            "ê²€ìƒ‰ì–´ ì‘ì„± ê·œì¹™:\n"
            "1. site:halla.ac.kr í•„ìˆ˜ í¬í•¨\n"
        )
        
        # ê³µì§€ì‚¬í•­ ê²€ìƒ‰ì´ë©´ í•­ìƒ í˜„ì¬ ì—°ë„ í¬í•¨
        if is_notice_query:
            rewrite_prompt += (
                f"2. **ì¤‘ìš”**: ê³µì§€ì‚¬í•­ ê²€ìƒ‰ì´ë¯€ë¡œ ë°˜ë“œì‹œ í˜„ì¬ ì—°ë„({year_str}ë…„)ë¥¼ ê²€ìƒ‰ì–´ì— í¬í•¨í•˜ì„¸ìš”\n"
                "3. ê³µì§€ì‚¬í•­ ê²€ìƒ‰ ì‹œ ë°˜ë“œì‹œ 'halla.ac.kr > ì»¤ë®¤ë‹ˆí‹° > ê³µì§€ì‚¬í•­' ê²½ë¡œ ëª…ì‹œ\n"
                "4. ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ê²€ìƒ‰ì–´ë¡œ êµ¬ì„±\n"
            )
        else:
            rewrite_prompt += (
                f"2. 'ìµœì‹ ', 'ìµœê·¼', 'ìš”ì¦˜' í‚¤ì›Œë“œ ë°œê²¬ ì‹œ ë°˜ë“œì‹œ í˜„ì¬ ì—°ë„({year_str}ë…„)ë¥¼ ê²€ìƒ‰ì–´ì— í¬í•¨í•˜ì„¸ìš”\n"
                "3. ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ê²€ìƒ‰ì–´ë¡œ êµ¬ì„±\n"
            )
        
        # preferredê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì •ë³´ë¡œ í™œìš©
        if preferred:
            rewrite_prompt += f"\n[ì¶”ì²œ URL] {preferred}\nì´ URLì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ìš°ì„  ê²€ìƒ‰í•˜ì„¸ìš”.\n"
        
        provider = get_provider("search_rewrite")
        messages = [{"role": "user", "content": [{"type": "input_text", "text": rewrite_prompt}]}]
        search_text, usage = await provider.simple_completion(messages)
        search_text = search_text.strip()

        # âœ… API usage ê¸°ë°˜ í† í° ê³„ì‚°
        if token_counter and usage:
            token_counter.update_from_api_usage(
                usage=usage,
                role="search_rewrite",
                model=provider.get_model_name(),
                category="function"
            )
        print(f"[WEB] final_search_text='{search_text}'")

        context_input = [{
            "role": "user",
            "content": [{"type": "input_text", "text": search_text}]
        }]

        call_ts = time.time()
        response = client.responses.create(
            model=model.advanced,
            input=context_input,
            text={"format": {"type": "text"}},
            reasoning={},
            tools=[{
                "type": "web_search_preview",
                "user_location": {"type": "approximate", "country": "KR"},
                "search_context_size": "medium"
            }],
            tool_choice={"type": "web_search_preview"},
            temperature=1,
            max_output_tokens=2048,
            top_p=1,
            store=True
        )
        print(f"[WEB] openai.responses.create elapsed={time.time()-call_ts:.2f}s total={time.time()-start_ts:.2f}s")

        # âœ… API usage ì¶”ì  (web_search ì—­í• )
        if token_counter:
            if hasattr(response, 'usage') and response.usage:
                # API usage ì •ë³´ ì¶”ì¶œ
                input_tok = getattr(response.usage, "input_tokens", 0)
                output_tok = getattr(response.usage, "output_tokens", 0)

                # reasoning_tokens ì¶”ì¶œ (í•„ìš”ì‹œ)
                reasoning_tok = 0
                if hasattr(response.usage, 'output_tokens_details') and response.usage.output_tokens_details:
                    reasoning_tok = getattr(response.usage.output_tokens_details, 'reasoning_tokens', 0)

                # total_tokens ê³„ì‚°
                total_tok = getattr(response.usage, "total_tokens", input_tok + output_tok)

                usage_data = {
                    "input_tokens": input_tok,
                    "output_tokens": output_tok,
                    "reasoning_tokens": reasoning_tok,
                    "total_tokens": total_tok,
                }

                token_counter.update_from_api_usage(
                    usage=usage_data,
                    role="web_search",
                    model=model.advanced,  # gpt-4.1
                    category="function",
                    replace=False
                )
                print(f"[TokenTrack][web_search] âœ… API usage tracked: input={input_tok}, output={output_tok}, reasoning={reasoning_tok}")
            else:
                print(f"[TokenTrack][web_search] âš ï¸ No API usage available")

        did_call = any(getattr(item, "type", None) == "web_search_call" for item in getattr(response, "output", []))
        print(f"[WEB] search_call_performed={did_call}")

        message = next((item for item in response.output if getattr(item, "type", None) == "message"), None)
        if not message:
            return "âŒ GPT ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        content_block = next((block for block in message.content if getattr(block, "type", None) == "output_text"), None)
        if not content_block:
            return "âŒ GPT ì‘ë‹µ ë‚´ output_text í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        output_text = getattr(content_block, "text", "").strip()
        annotations = getattr(content_block, "annotations", [])
        citations = []
        for a in annotations:
            if getattr(a, "type", None) == "url_citation":
                title = getattr(a, "title", "ì¶œì²˜")
                url = getattr(a, "url", "")
                if url:
                    citations.append(f"[{title}]({url})")
        result = output_text
        if citations:
            result += "\n\nğŸ“ ì¶œì²˜:\n" + "\n".join(citations)
        print(f"[WEB][END] success total_elapsed={time.time()-start_ts:.2f}s")
        return result + "\n[WEB_METADATA]elapsed={:.2f}s did_call={}".format(time.time()-start_ts, did_call)
    except Exception as e:
        print(f"[WEB][ERROR] {e} total_elapsed={time.time()-start_ts:.2f}s")
        return f"ğŸš¨ ì›¹ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"


def _parse_date_input(date_text: Optional[str]) -> datetime.date:
    today = datetime.now().date()
    if not date_text:
        return today
    s = str(date_text).strip()
    # ìƒëŒ€ ë‚ ì§œ ì§€ì›
    if s in ("ì˜¤ëŠ˜", "today"):
        return today
    if s in ("ë‚´ì¼", "tomorrow"):
        return today + timedelta(days=1)
    if s in ("ì–´ì œ", "yesterday"):
        return today - timedelta(days=1)
    if s in ("ëª¨ë ˆ", "day after tomorrow"):
        return today + timedelta(days=2)
    if s in ("ê¸€í”¼", "3 days later"):
        return today + timedelta(days=3)
    # Normalize separators and parse flexibly (YYYY.M.D or YYYY.MM.DD)
    s_norm = s.replace("/", ".").replace("-", ".")
    parts = s_norm.split(".")
    if len(parts) == 3 and all(p.isdigit() for p in parts):
        y, m, d = map(int, parts)
        return datetime(year=y, month=m, day=d).date()
    # í•œêµ­ì–´ í‘œê¸°: 9ì›” 7ì¼ (ì—°ë„ ìƒëµ ì‹œ ì˜¬í•´)
    m = re.search(r"(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼", s)
    if m:
        y = today.year
        month = int(m.group(1))
        day = int(m.group(2))
        return datetime(year=y, month=month, day=day).date()
    raise ValueError("ë‚ ì§œ í˜•ì‹ì€ YYYY-MM-DD / YYYY.M.D / 'ì˜¤ëŠ˜/ë‚´ì¼/ì–´ì œ'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")


async def get_halla_cafeteria_menu(date: Optional[str] = None, meal: Optional[str] = None, cafeteria_type: Optional[str] = None) -> str:
    """ì›ì£¼ í•œë¼ëŒ€ ì‹ë‹¹(í•™ìƒì‹ë‹¹/êµì§ì›ì‹ë‹¹) ì£¼ê°„ ì‹ë‹¨ í˜ì´ì§€ë¥¼ íŒŒì‹±í•˜ì—¬ íŠ¹ì • ë‚ ì§œ/ë¼ë‹ˆ ë©”ë‰´ë¥¼ ë°˜í™˜.

    Args:
        date: ì¡°íšŒí•  ë‚ ì§œ ("ì˜¤ëŠ˜", "ë‚´ì¼", "YYYY-MM-DD" ë“±)
        meal: ì¡°íšŒí•  ë¼ë‹ˆ ("ì¡°ì‹", "ì¤‘ì‹", "ì„ì‹", Noneì´ë©´ ì „ì²´)
        cafeteria_type: ì‹ë‹¹ ì¢…ë¥˜ ('í•™ìƒ' ë˜ëŠ” 'êµì§ì›', ê¸°ë³¸ê°’: 'í•™ìƒ')

    ì œí•œ: ì„œë²„ê°€ ì£¼ì°¨ ë³€ê²½ì„ JS/í¼ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ ê³¼ê±°/ë¯¸ë˜ ì£¼ ì„ íƒì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ. ì´ ê²½ìš° í˜„ì¬ ì£¼ë§Œ ë°˜í™˜.
    """
    # cafeteria_type ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •
    if cafeteria_type is None or cafeteria_type not in ["í•™ìƒ", "êµì§ì›"]:
        cafeteria_type = "í•™ìƒ"
    
    t0 = time.time()
    print(f"[CAF][START] date={date} meal={meal} cafeteria_type={cafeteria_type}")
    try:
        target_date = _parse_date_input(date)
    except Exception as e:
        print(f"[CAF][ERROR] date-parse {e}")
        return f"âŒ ë‚ ì§œ í•´ì„ ì‹¤íŒ¨: {e}"

    # URL ë¶„ê¸°: êµì§ì›ì‹ë‹¹ì€ /kr/212/, í•™ìƒì‹ë‹¹ì€ /kr/211/
    if cafeteria_type == "êµì§ì›":
        url = "https://www.halla.ac.kr/kr/212/subview.do"
    else:
        url = "https://www.halla.ac.kr/kr/211/subview.do"
    try:
        net_t = time.time()
        async with httpx.AsyncClient() as client:
            resp = await client.get(url, timeout=10.0)
            resp.raise_for_status()
            html_content = resp.text
        print(f"[CAF] fetch ok elapsed={time.time()-net_t:.2f}s status={resp.status_code}")
    except Exception as e:
        print(f"[CAF][ERROR] fetch {e}")
        return f"âŒ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}"

    soup = BeautifulSoup(html_content, "html.parser")

    # ì£¼ê°„ ë²”ìœ„ í…ìŠ¤íŠ¸ ì°¾ê¸° (ì˜ˆ: 2025.08.25 ~ 2025.08.31)
    text = soup.get_text("\n", strip=True)
    m = re.search(r"(\d{4}\.\d{2}\.\d{2})\s*~\s*(\d{4}\.\d{2}\.\d{2})", text)
    week_start = week_end = None
    if m:
        try:
            week_start = datetime.strptime(m.group(1), "%Y.%m.%d").date()
            week_end = datetime.strptime(m.group(2), "%Y.%m.%d").date()
        except Exception:
            pass

    # í˜„ì¬ ì£¼ í™•ì¸ ë° ëŒ€ìƒ ë‚ ì§œê°€ í•´ë‹¹ ì£¼ì— í¬í•¨ë˜ëŠ”ì§€ ì²´í¬
    if week_start and week_end and not (week_start <= target_date <= week_end):
        # ë‹¤ë¥¸ ì£¼ì¼ ê²½ìš°, ì„œë²„ê°€ íŒŒë¼ë¯¸í„° ì—†ì´ í˜„ì¬ ì£¼ë§Œ ì œê³µí•˜ë©´ í•œê³„ ì•ˆë‚´
        info = f"í˜„ì¬ í˜ì´ì§€ëŠ” {week_start}~{week_end} ì£¼ê°„ ì‹ë‹¨ì…ë‹ˆë‹¤."
        return info + " ì›í•˜ëŠ” ë‚ ì§œëŠ” ë‹¤ë¥¸ ì£¼ì…ë‹ˆë‹¤. í˜ì´ì§€ê°€ ì£¼ì°¨ íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•˜ì§€ ì•Šì•„ í˜„ì¬ ì£¼ë§Œ ì¡°íšŒ ê°€ëŠ¥í•©ë‹ˆë‹¤: " + url

    # í…Œì´ë¸” íƒìƒ‰: ìš”ì¼ í—¤ë”ì™€ ë¼ë‹ˆ ë¼ë²¨ì´ ìˆëŠ” í‘œë¥¼ ì°¾ì•„ íŒŒì‹±
    tables = soup.find_all("table")

    days = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
    weekday_idx = target_date.weekday()  # 0=ì›”
    target_day_label = days[weekday_idx]

    def clean(txt: str) -> str:
        return re.sub(r"\s+", " ", txt).strip()

    def pick_table_and_parse() -> dict:
        # ë°˜í™˜: {"ì¡°ì‹": str|None, "ì¤‘ì‹": str|None, "ì„ì‹": str|None}
        result = {"ì¡°ì‹": None, "ì¤‘ì‹": None, "ì„ì‹": None}
        for tbl in tables:
            rows = tbl.find_all("tr")
            if not rows:
                continue
            # 1) ìš”ì¼ ì—´ ì¸ë±ìŠ¤ ë§¤í•‘ ì°¾ê¸° (í—¤ë” 1~2í–‰ì„ ì‚´í´ë´„)
            day_col_index = None
            header_candidates = rows[:2] if len(rows) >= 2 else rows[:1]
            for hdr in header_candidates:
                cells = hdr.find_all(["th", "td"])
                for i, c in enumerate(cells):
                    txt = clean(c.get_text())
                    if target_day_label in txt or (txt.endswith("ìš”ì¼") and target_day_label in txt):
                        day_col_index = i
                        break
                if day_col_index is not None:
                    break

            # ì¼ë¶€ í‘œëŠ” ì²« ì—´ì´ 'êµ¬ë¶„', ì´í›„ ì›”~ì¼ì´ë¯€ë¡œ day_col_indexë¥¼ ëª» ì°¾ìœ¼ë©´ ì›”~ì¼ íŒ¨í„´ìœ¼ë¡œ ì¶”ì •
            if day_col_index is None:
                # í—¤ë” í–‰ì—ì„œ ì›”~ì¼ì´ ì—°ì†ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸
                for hdr in header_candidates:
                    cells = [clean(c.get_text()) for c in hdr.find_all(["th", "td"])]
                    if any(d in "".join(cells) for d in days):
                        # ê¸°ë³¸ì ìœ¼ë¡œ ì²« ì—´ì´ ë¼ë²¨, ì´í›„ ì›”=1, í™”=2 ...ë¡œ ê°€ì •
                        day_col_index = 1 + weekday_idx
                        break

            if day_col_index is None:
                continue

            # 2) ë¼ë‹ˆ ë¼ë²¨ í–‰ì„ ì°¾ì•„ í•´ë‹¹ ìš”ì¼ ì—´ì˜ ì…€ì„ ì¶”ì¶œ
            for tr in rows:
                cells = tr.find_all(["th", "td"])
                if not cells:
                    continue
                label = clean(cells[0].get_text()) if cells else ""
                # ë¼ë‹ˆëª…ì€ ë³€í˜•ë  ìˆ˜ ìˆì–´ ë¶€ë¶„ ì¼ì¹˜ í—ˆìš© (ì˜ˆ: ì¤‘ì‹(11:30~13:30))
                for meal_label in list(result.keys()):
                    if meal_label in label:
                        # ìš”ì¼ ì—´ì´ ë²”ìœ„ ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
                        if len(cells) > day_col_index:
                            result[meal_label] = clean(cells[day_col_index].get_text())
            # í•˜ë‚˜ë¼ë„ ìˆ˜ì§‘ë˜ì—ˆìœ¼ë©´ ì´ í…Œì´ë¸”ì„ ì±„íƒ
            if any(v for v in result.values()):
                return result
        return result

    parse_t = time.time()
    found = pick_table_and_parse()
    print(f"[CAF] primary-parse elapsed={time.time()-parse_t:.2f}s result={found}")

    # í´ë°±: í‘œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ë¼ì¸ ê¸°ë°˜ ì¶”ë¡ (ë¶€ì •í™•í•  ìˆ˜ ìˆìŒ)
    if all(v is None for v in found.values()):
        lines = [l for l in text.split("\n") if l]
        # ë§¤ìš° ë‹¨ìˆœ ì¶”ì •: 'ì¤‘ì‹ | ...' ê°™ì€ ë¼ì¸ì´ ìˆìœ¼ë©´ ê·¸ ë‹¤ìŒ í† í°ë“¤ì„ ì‚¬ìš©
        for key in list(found.keys()):
            for ln in lines:
                if key in ln and "|" in ln:
                    # íŒŒì´í”„ êµ¬ë¶„ìœ¼ë¡œ ë¶„í•´ í›„ ìš”ì¼ ì¸ë±ìŠ¤ ì‚¬ìš©
                    parts = [clean(p) for p in ln.split("|")]
                    # parts ì˜ˆ: [ë¼ë²¨, ì¡°ì‹, ì›”, í™”, ìˆ˜, ...] í˜•íƒœì¼ ìˆ˜ ìˆìŒ â†’ ì›”ì´ partsì—ì„œ ì–´ë””ì— ìˆëŠ”ì§€ ë™ì ìœ¼ë¡œ íƒìƒ‰
                    try:
                        # ì›”~ì¼ ì¤‘ target_day_labelì˜ ì²« ë“±ì¥ ìœ„ì¹˜ë¥¼ ì°¾ìŒ
                        day_pos = None
                        for i, token in enumerate(parts):
                            if token.startswith(target_day_label):
                                day_pos = i
                                break
                        if day_pos is None:
                            # ê¸°ë³¸ ì˜¤í”„ì…‹ ê°€ì •: [ë¼ë²¨, ë¼ë‹ˆ, ì›”, í™”, ìˆ˜, ...]
                            base = 2
                            day_pos = base + weekday_idx
                        if len(parts) > day_pos:
                            found[key] = parts[day_pos]
                    except Exception:
                        pass
                        break

    # ê²°ê³¼ êµ¬ì„±
    day_label = target_day_label
    cafeteria_label = "êµì§ì›ì‹ë‹¹" if cafeteria_type == "êµì§ì›" else "í•™ìƒì‹ë‹¹"
    header = f"í•œë¼ëŒ€ {cafeteria_label} ì‹ë‹¨ ({target_date} {day_label})"

    if meal in ("ì¡°ì‹", "ì¤‘ì‹", "ì„ì‹"):
        val = found.get(meal)
        if not val:
            out = header + f"\n[{meal}] ì •ë³´ ì—†ìŒ\nì¶”ê°€ ì‚¬í•­: ì›ë¬¸: {url}"
            print(f"[CAF][END] elapsed={time.time()-t0:.2f}s meal-miss")
            return out
        out = header + f"\n[{meal}] {val}\nì¶”ê°€ ì‚¬í•­: ì›ë¬¸: {url}"
        print(f"[CAF][END] elapsed={time.time()-t0:.2f}s meal-hit")
        return out

    # 3ë¼ ëª¨ë‘ ë°˜í™˜
    lines_out = []
    for k in ["ì¡°ì‹", "ì¤‘ì‹", "ì„ì‹"]:
        v = found.get(k)
        lines_out.append(f"[{k}] {v if v else 'ì •ë³´ ì—†ìŒ'}")
    out = header + "\n" + "\n".join(lines_out) + f"\nì¶”ê°€ ì‚¬í•­: ì›ë¬¸: {url}"
    print(f"[CAF][END] elapsed={time.time()-t0:.2f}s all-meals")
    return out


def _parse_month_input(month_text: Optional[str]) -> tuple:
    """ì›” ì…ë ¥ì„ íŒŒì‹±í•˜ì—¬ (ë…„, ì›”) íŠœí”Œ ë°˜í™˜

    Args:
        month_text: ì›” ì…ë ¥ ("ì´ë²ˆë‹¬", "ë‹¤ìŒë‹¬", "2025-03", "3ì›”" ë“±)

    Returns:
        (year, month) íŠœí”Œ
    """
    today = datetime.now().date()

    if not month_text:
        return (today.year, today.month)

    s = str(month_text).strip()

    # ìƒëŒ€ ì›” ì§€ì›
    if s in ("ì´ë²ˆë‹¬", "ì´ë²ˆ ë‹¬", "í˜„ì¬", "this month"):
        return (today.year, today.month)
    if s in ("ë‹¤ìŒë‹¬", "ë‹¤ìŒ ë‹¬", "next month"):
        next_month = today.replace(day=1) + timedelta(days=32)
        return (next_month.year, next_month.month)
    if s in ("ì§€ë‚œë‹¬", "ì§€ë‚œ ë‹¬", "last month"):
        prev_month = today.replace(day=1) - timedelta(days=1)
        return (prev_month.year, prev_month.month)

    # YYYY-MM í˜•ì‹
    if re.match(r"^\d{4}-\d{1,2}$", s):
        parts = s.split("-")
        return (int(parts[0]), int(parts[1]))

    # YYYYë…„ MMì›” í˜•ì‹
    m = re.search(r"(\d{4})ë…„\s*(\d{1,2})ì›”", s)
    if m:
        return (int(m.group(1)), int(m.group(2)))

    # MMì›” í˜•ì‹ (ì˜¬í•´)
    m = re.search(r"(\d{1,2})ì›”", s)
    if m:
        return (today.year, int(m.group(1)))

    # ìˆ«ìë§Œ (1~12: ì›”, ê·¸ ì™¸: í˜„ì¬ ì›”)
    if s.isdigit():
        num = int(s)
        if 1 <= num <= 12:
            return (today.year, num)

    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í˜„ì¬ ì›”
    return (today.year, today.month)


async def get_halla_academic_calendar(month: Optional[str] = None) -> str:
    """í•œë¼ëŒ€í•™êµ í•™ì‚¬ì¼ì • ì¡°íšŒ

    Args:
        month: ì¡°íšŒí•  ì›” ("ì´ë²ˆë‹¬", "ë‹¤ìŒë‹¬", "2025-03", "3ì›”" ë“±)

    Returns:
        í•™ì‚¬ì¼ì • ì •ë³´ ë¬¸ìì—´
    """
    t0 = time.time()
    print(f"[CALENDAR][START] month={month}")

    try:
        year, month_num = _parse_month_input(month)
    except Exception as e:
        print(f"[CALENDAR][ERROR] month-parse {e}")
        return f"âŒ ì›” í•´ì„ ì‹¤íŒ¨: {e}"

    url = "https://www.halla.ac.kr/kr/100/subview.do"

    try:
        net_t = time.time()
        # íŠ¹ì • ë…„ì›” ì¡°íšŒ ì‹œë„ (íŒŒë¼ë¯¸í„° ì „ë‹¬)
        params = {"year": str(year), "month": str(month_num)}
        async with httpx.AsyncClient() as client:
            resp = await client.get(url, params=params, timeout=10.0)
            resp.raise_for_status()
            html_content = resp.text
        print(f"[CALENDAR] fetch ok elapsed={time.time()-net_t:.2f}s status={resp.status_code}")
    except Exception as e:
        print(f"[CALENDAR][ERROR] fetch {e}")
        return f"âŒ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}"

    soup = BeautifulSoup(html_content, "html.parser")

    schedules = []

    # ë°©ë²• 1: ul íƒœê·¸ì—ì„œ li í•­ëª© ì°¾ê¸°
    ul_tags = soup.find_all("ul")
    for ul in ul_tags:
        li_items = ul.find_all("li")
        for li in li_items:
            text = li.get_text("\n", strip=True)
            # "MM.DD" íŒ¨í„´ì´ í¬í•¨ëœ lië§Œ ì²˜ë¦¬
            if re.search(r"\d{1,2}\.\d{1,2}", text):
                # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€ê²½í•˜ê³  ì •ë¦¬
                cleaned = " ".join(text.split())
                if len(cleaned) > 5:  # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ
                    schedules.append(cleaned)

    # ë°©ë²• 2: ulì—ì„œ ëª» ì°¾ì•˜ìœ¼ë©´, ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ë§¤ì¹­
    if not schedules:
        text = soup.get_text("\n", strip=False)
        lines = text.split("\n")

        # "MM.DD" íŒ¨í„´ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ ì°¾ê¸°
        schedule_pattern = re.compile(r"(\d{1,2}\.\d{1,2})")

        i = 0
        while i < len(lines):
            line = lines[i].strip()
            match = schedule_pattern.match(line)

            if match:
                # ë‚ ì§œ ë¼ì¸ ë°œê²¬
                date_str = match.group(1)

                # ë‹¤ìŒ ë¼ì¸ì´ ì¼ì • ë‚´ìš©ì¼ ê°€ëŠ¥ì„±
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()

                    # ë²”ìœ„ ë‚ ì§œ ì²´í¬ (ì˜ˆ: "11.24 - 11.25")
                    if next_line.startswith("-") and i + 2 < len(lines):
                        # "- 11.25" í˜•íƒœ
                        range_match = re.match(r"-\s*(\d{1,2}\.\d{1,2})", next_line)
                        if range_match:
                            end_date = range_match.group(1)
                            date_str = f"{date_str} - {end_date}"
                            i += 1  # ë‹¤ìŒ ë¼ì¸ ê±´ë„ˆë›°ê¸°

                            # ê·¸ ë‹¤ìŒ ë¼ì¸ì´ ì¼ì • ë‚´ìš©
                            if i + 1 < len(lines):
                                next_line = lines[i + 1].strip()

                    # ì¼ì • ë‚´ìš©ì¸ì§€ í™•ì¸ (ë‚ ì§œ íŒ¨í„´ì´ ì•„ë‹ˆê³ , ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸)
                    if next_line and not schedule_pattern.match(next_line) and len(next_line) > 1:
                        schedules.append(f"{date_str}: {next_line}")
                        i += 1  # ë‹¤ìŒ ë¼ì¸ ê±´ë„ˆë›°ê¸°

            i += 1

    # ê²°ê³¼ êµ¬ì„±
    header = f"í•œë¼ëŒ€ í•™ì‚¬ì¼ì • ({year}ë…„ {month_num}ì›”)"

    if not schedules:
        out = header + f"\në“±ë¡ëœ ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤.\nì›ë¬¸: {url}"
        print(f"[CALENDAR][END] elapsed={time.time()-t0:.2f}s no-schedule")
        return out

    out = header + "\n" + "\n".join(schedules) + f"\n\nì›ë¬¸: {url}"
    print(f"[CALENDAR][END] elapsed={time.time()-t0:.2f}s schedules={len(schedules)}")
    return out


# í†µí•™ë²„ìŠ¤ ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_shuttle_bus_service = None

def _get_shuttle_bus_service():
    """ShuttleBusService ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _shuttle_bus_service
    if _shuttle_bus_service is None:
        _shuttle_bus_service = ShuttleBusService()
    return _shuttle_bus_service


async def get_shuttle_bus_info(user_query: str, chat_context=None, token_counter=None) -> str:
    """í•œë¼ëŒ€í•™êµ í†µí•™ë²„ìŠ¤ ì •ë³´ ì œê³µ

    Args:
        user_query: ì‚¬ìš©ìì˜ í†µí•™ë²„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸
        chat_context: ëŒ€í™” ë¬¸ë§¥ (ìµœê·¼ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸)
        token_counter: í† í° ì¹´ìš´í„°

    Returns:
        í†µí•™ë²„ìŠ¤ ì •ë³´ ì‘ë‹µ ë¬¸ìì—´
    """
    start_ts = time.time()
    print(f"[SHUTTLE][START] query='{user_query}' chat_ctx={'Y' if chat_context else 'N'}")

    try:
        # ëŒ€í™” ë¬¸ë§¥ ì¶”ì¶œ
        if chat_context:
            recent_messages = chat_context[-4:]
            context_info = "\n".join([
                f"{m.get('role','unknown')}: {m.get('content','')}"
                for m in recent_messages if m.get('role') != 'system'
            ])
        else:
            context_info = ""

        # ShuttleBusService ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        service = _get_shuttle_bus_service()

        # 1ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        category = await service.classify_category(
            user_input=user_query,
            context_info=context_info,
            token_counter=token_counter
        )

        print(f"[SHUTTLE] category={category}")

        # í†µí•™ë²„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ì´ ì•„ë‹Œ ê²½ìš°
        if category == "not_shuttle_bus":
            elapsed = time.time() - start_ts
            print(f"[SHUTTLE][END] elapsed={elapsed:.2f}s result=not_shuttle_bus")
            return "í†µí•™ë²„ìŠ¤ì™€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤. ì‹œë‚´ë²„ìŠ¤, ì‹œì™¸ë²„ìŠ¤ ì‹œê°„í‘œ, ì˜ˆì•½ ë°©ë²• ë“±ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."

        # 2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ë³„ ì •ë³´ ì¶”ì¶œ
        shuttle_info = service.get_info_by_category(category, user_query)
        print(f"[SHUTTLE] info extracted len={len(shuttle_info)}")

        # 3ë‹¨ê³„: ì‘ë‹µ ìƒì„±
        response = await service.generate_response(
            user_input=user_query,
            shuttle_info=shuttle_info,
            token_counter=token_counter
        )

        elapsed = time.time() - start_ts
        print(f"[SHUTTLE][END] elapsed={elapsed:.2f}s response_len={len(response)}")

        return response

    except Exception as e:
        elapsed = time.time() - start_ts
        print(f"[SHUTTLE][ERROR] elapsed={elapsed:.2f}s error={e}")
        import traceback
        traceback.print_exc()
        return f"âŒ í†µí•™ë²„ìŠ¤ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


class FunctionCalling:
    def __init__(self, model, available_functions=None, token_counter=None):
        self.model = model
        self.token_counter = token_counter
        default_functions = {
            "search_internet": search_internet,
            "get_halla_cafeteria_menu": get_halla_cafeteria_menu,
            "get_halla_academic_calendar": get_halla_academic_calendar,
            "get_shuttle_bus_info": get_shuttle_bus_info,
        }

        if available_functions:
            default_functions.update(available_functions)

        self.available_functions = default_functions
       
    async def analyze(self, user_message, tools):
        """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ í•¨ìˆ˜ì™€ íŒë‹¨ ê·¼ê±°ë¥¼ ë°˜í™˜

        Returns:
            dict: {
                "reasoning": str (íŒë‹¨ ê·¼ê±°),
                "output": list (í•¨ìˆ˜ í˜¸ì¶œ ëª©ë¡, ê¸°ì¡´ response.output í˜•ì‹)
            }
        """
        if not user_message or user_message.strip() == "":
            return {
                "reasoning": "ì…ë ¥ì´ ë¹„ì–´ìˆì–´ í•¨ìˆ˜ë¥¼ ì„ íƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "output": []
            }
        
        # 1ë‹¨ê³„: LLMìœ¼ë¡œ í•¨ìˆ˜ ì„ íƒ ì´ìœ  ìƒì„± (structured output)
        reasoning = None
        try:
            from app.ai.chatbot import character
            from app.ai.llm import get_provider
            
            prompt = [
                {"role": "system", "content": character.decide_function},
                {"role": "user", "content": user_message},
            ]
            
            schema = {
                "type": "object",
                "properties": {
                    "reasoning": {"type": "string"},
                    "selected_tools": {
                        "type": "array",
                        "items": {"type": "string"}
                    }
                },
                "required": ["reasoning", "selected_tools"],
                "additionalProperties": False,
            }
            
            provider = get_provider("function_analyze")
            raw, usage = await provider.structured_completion(prompt, schema)
            raw = raw.strip()

            # âœ… API usage ê¸°ë°˜ í† í° ê³„ì‚°
            if self.token_counter and usage:
                self.token_counter.update_from_api_usage(
                    usage=usage,
                    role="function_analyze",
                    model=provider.get_model_name(),
                    category="function"
                )
            
            if raw:
                payload = json.loads(raw)
                reasoning = payload.get("reasoning", "").strip() or None
                selected_tools = payload.get("selected_tools", [])
        except Exception as e:
            reasoning = f"ì¶”ë¡  ìƒì„± ì‹¤íŒ¨ ({e})"
            selected_tools = []  # exception ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ì„¤ì •

        # 2ë‹¨ê³„: ê¸°ì¡´ í•¨ìˆ˜ í˜¸ì¶œ ë¶„ì„ (OpenAI API)

        # í˜„ì¬ ë‚ ì§œ ì •ë³´ ìƒì„±
        current_date = datetime.now()
        date_info = current_date.strftime("%Yë…„ %mì›” %dì¼ (%A)")
        weekday_map = {
            "Monday": "ì›”ìš”ì¼", "Tuesday": "í™”ìš”ì¼", "Wednesday": "ìˆ˜ìš”ì¼",
            "Thursday": "ëª©ìš”ì¼", "Friday": "ê¸ˆìš”ì¼", "Saturday": "í† ìš”ì¼", "Sunday": "ì¼ìš”ì¼"
        }
        weekday_kr = weekday_map.get(current_date.strftime("%A"), "")
        date_info = current_date.strftime(f"%Yë…„ %mì›” %dì¼ ({weekday_kr})")

        structured_input = [
            {
                "role": "system",
                "content": f"""í˜„ì¬ ë‚ ì§œ: {date_info}

[í•„ìˆ˜ ê·œì¹™]
í•œêµ­ì–´ ë‚ ì§œ ìˆœì„œ: ì˜¤ëŠ˜(0ì¼) â†’ ë‚´ì¼(1ì¼) â†’ ëª¨ë ˆ(2ì¼) â†’ ê¸€í”¼(3ì¼)
ì¶œë ¥ í˜•ì‹: "ì˜¤ëŠ˜", "ë‚´ì¼", "ëª¨ë ˆ", "ê¸€í”¼", "YYYY-MM-DD" ì¤‘ í•˜ë‚˜
- ìƒëŒ€ í‘œí˜„: "Nì¼ í›„" â†’ ì •í™•íˆ Nì¼ ë”í•˜ê¸°
- ìì—°ì–´ ë‚ ì§œ: "ë‹¤ìŒì£¼ ì›”ìš”ì¼" â†’ YYYY-MM-DDë¡œ ê³„ì‚°
- ë‚ ì§œ ë¯¸ì–¸ê¸‰: "ì˜¤ëŠ˜"

[ì£¼ì˜ì‚¬í•­]
ì‚¬ìš©ìê°€ ì˜¤íƒ€ë‚˜ ì• ë§¤í•œ ë‚ ì§œ í‘œí˜„ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì€ ì˜ˆì‹œì´ë©°, ì´ì™€ ìœ ì‚¬í•œ íŒ¨í„´ì— ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•˜ì„¸ìš”:
- ì˜¤íƒ€ ì˜ˆì‹œ: "ì•¼ëª¨ë ˆ"â†’"ëª¨ë ˆ", "ê¸€ì„í”¼"â†’"ê¸€í”¼", "ê·¸ì„í”¼"â†’"ê¸€í”¼"
- ë„ì–´ì“°ê¸° ì˜¤ë¥˜, ìëª¨ ë¶„ë¦¬ ë“± ë‹¤ì–‘í•œ í˜•íƒœ ê°€ëŠ¥
- ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš° ë¬¸ë§¥ê³¼ ìƒì‹ìœ¼ë¡œ íŒë‹¨í•˜ë˜, ì‚¬ìš©ì ì˜ë„ì— ê°€ì¥ ê°€ê¹Œìš´ í•´ì„ ì„ íƒ

ìœ„ ì˜ˆì‹œëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤. ì‹¤ì œ ì…ë ¥ì˜ ë§¥ë½ì„ ìš°ì„ í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ í•´ì„í•˜ì„¸ìš”."""
            },
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": user_message}
                ],
            }
        ]
        try:
            response = client.responses.create(
                model=model.o3_mini,
                input=structured_input,
                tools=tools,
                tool_choice="auto",
            )

            if self.token_counter and hasattr(response, 'usage') and response.usage:
                usage_data = {
                    "input_tokens": getattr(response.usage, "input_tokens", 0),
                    "output_tokens": getattr(response.usage, "output_tokens", 0),
                    "total_tokens": getattr(response.usage, "total_tokens", 0),
                    "reasoning_tokens": getattr(response.usage.output_tokens_details, 'reasoning_tokens', 0) if hasattr(response.usage, 'output_tokens_details') else 0,
                }
                self.token_counter.update_from_api_usage(
                    usage=usage_data,
                    role="function_calling",
                    model=model.o3_mini,
                    category="function",
                    replace=False
                )

            return {
                "reasoning": reasoning,
                "selected_tools": selected_tools,  # reasoningì—ì„œ ì„ íƒëœ ë„êµ¬ ëª©ë¡ ì¶”ê°€
                "output": response.output
            }
        except Exception as e:
            return {
                "reasoning": reasoning,
                "selected_tools": selected_tools,
                "output": []
            }
    

###   ë ˆê±°ì‹œ def run(self, analyzed,context):
        ''' analyzed_dict: í•¨ìˆ˜ í˜¸ì¶œ ì •ë³´, context: í˜„ì¬ ë¬¸ë§¥'''
        context.append(analyzed)
        for tool_call in analyzed:
            if tool_call.get("type") != "function_call":
                continue
            function=tool_call["function"]
            func_name=function["name"]
            #ì‹¤ì œ í•¨ìˆ˜ì™€ ì—°ê²°
            func_to_call = self.available_functions[func_name]

            try:

                func_args=json.loads(function["arguments"])#ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜-> ë¬¸ìì—´ì´ jsoní˜•íƒœì…-> ì´ê±¸ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                
                if func_name == "search_internet":
                    # contextëŠ” ì´ë¯¸ run ë©”ì„œë“œì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ê³  ìˆìŒ
                    func_response = func_to_call(chat_context=context[:], **func_args)
                else:
                    func_response=func_to_call(**func_args)
                context.append({
                    "tool_call_id": tool_call["id"],
                    "role": "tool",
                    "name": func_name, 
                    "content": str(func_response),
                    "parallel_tool_calls": True
                })#ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¬¸ë§¥ì— ì¶”ê°€
  

            except Exception as e:
                print("Error occurred(run):",e)
                return makeup_response("[run ì˜¤ë¥˜ì…ë‹ˆë‹¤]")

        # í•¨ìˆ˜ ì‹¤í–‰ í›„ ìµœì¢… ì‘ë‹µ ìƒì„±
        response = client.responses.create(model=self.model, input=context)

        # âœ… API usage ì¶”ì  (function_calling ì—­í•  - ì¬í˜¸ì¶œ)
        if self.token_counter and hasattr(response, 'usage') and response.usage:
            usage_data = {
                "input_tokens": getattr(response.usage, "input_tokens", 0),
                "output_tokens": getattr(response.usage, "output_tokens", 0),
                "total_tokens": getattr(response.usage, "total_tokens", 0),
                "reasoning_tokens": getattr(response.usage.output_tokens_details, 'reasoning_tokens', 0) if hasattr(response.usage, 'output_tokens_details') else 0,
            }
            self.token_counter.update_from_api_usage(
                usage=usage_data,  # âœ… ìˆ˜ì •: usage_info â†’ usage
                role="function_calling",
                model=self.model,  # âœ… ì¶”ê°€: í•„ìˆ˜ íŒŒë¼ë¯¸í„°
                category="function",
                replace=False
            )

        return response.model_dump()
    ###
   
    def call_function(self, analyzed_dict):        
        func_name = analyzed_dict["function_call"]["name"]
        func_to_call = self.available_functions[func_name]                
        try:            
            func_args = json.loads(analyzed_dict["function_call"]["arguments"])
            func_response = func_to_call(**func_args)
            return str(func_response)
        except Exception as e:
            print("Error occurred(call_function):",e)
            return makeup_response("[call_function ì˜¤ë¥˜ì…ë‹ˆë‹¤]")
    