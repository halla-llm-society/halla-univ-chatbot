import json
import requests
import httpx
from pprint import pprint
import re
import time
import logging
from datetime import datetime, timedelta
from typing import Optional
from bs4 import BeautifulSoup
import os
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv
from dataclasses import dataclass

logger = logging.getLogger(__name__)

# LLM Manager import
try:
    from app.ai.llm import get_provider
except ImportError:
    # ìƒëŒ€ ê²½ë¡œë¡œ ì‹œë„
    from ..llm import get_provider

# ShuttleBus Service import
try:
    from app.ai.functions.shuttle_bus_service import ShuttleBusService
except ImportError:
    from .shuttle_bus_service import ShuttleBusService

# ìˆœí™˜ ì°¸ì¡° ë°©ì§€: config ëŒ€ì‹  ì§ì ‘ ìƒì„±
_BASE_DIR = Path(__file__).resolve().parent.parent.parent  # app/
_DOTENV_PATH = _BASE_DIR / "apikey.env"
load_dotenv(_DOTENV_PATH)

@dataclass(frozen=True)
class Model: 
    basic: str = "gpt-3.5-turbo-1106"
    advanced: str = "gpt-4.1"
    o3_mini: str = "o3-mini"
    o1: str = "o1"

model = Model()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key, max_retries=1)

def makeup_response(message, finish_reason="ERROR"):
    '''api ì‘ë‹µí˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì„œ
       ê°œë°œìê°€ ì„ì˜ë¡œ ìƒì„±í•œ ë©”ì„¸ì§€ë¥¼
       ê¸°ì¡´ ì¶œë ¥ í•¨ìˆ˜ë¡œ ì¶œë ¥í•˜ëŠ” ìš©ë„ì¸ í•¨ìˆ˜'''
    return {
        "choices": [
            {
                "finish_reason": finish_reason,
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": message
                }                   
            }
        ],
        "usage": {"total_tokens": 0},
    }

# í•¨ìˆ˜ ì •ì˜ëŠ” function_prompts.pyì—ì„œ ê°€ì ¸ì˜´
try:
    from app.ai.chatbot.function_prompts import get_function_definitions
    tools = get_function_definitions()
    logger.debug("[ANALYZER][INIT] âœ… Successfully imported function definitions from function_prompts.py")
except ImportError as e:
    # í´ë°±: ê¸°ì¡´ í•˜ë“œì½”ë”© ë°©ì‹
    logger.warning(f"[ANALYZER][INIT] âš ï¸ Failed to import function_prompts: {e}")
    logger.debug(f"[ANALYZER][INIT] Using fallback hardcoded function definitions")
    import traceback
    traceback.print_exc()
    tools = [
        
            {
            "type": "function",
            "name": "search_internet",
            "description": """ì¸í„°ë„·ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

            âš ï¸ ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°:
            - ìµœì‹  ê³µì§€ì‚¬í•­, ë‰´ìŠ¤, ì´ë²¤íŠ¸ ì •ë³´
            - í•œë¼ëŒ€í•™êµ ì›¹ì‚¬ì´íŠ¸ì˜ ìµœì‹  ì •ë³´
            - ì¼ë°˜ì ì¸ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°

            âŒ ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•˜ëŠ” ê²½ìš°:
            - í†µí•™ë²„ìŠ¤, ì…”í‹€ë²„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ â†’ get_shuttle_bus_info ì‚¬ìš©
            - í•™ì‹, ì‹ë‹¨ ê´€ë ¨ ì§ˆë¬¸ â†’ get_halla_cafeteria_menu ì‚¬ìš©
            - í•™ì‚¬ê·œì • ê´€ë ¨ ì§ˆë¬¸ â†’ RAG ì‹œìŠ¤í…œ ì‚¬ìš© (ìë™ ì²˜ë¦¬)

            í†µí•™ë²„ìŠ¤ ì‹œê°„í‘œ, íƒ‘ìŠ¹ ìœ„ì¹˜, ì˜ˆì•½ ë°©ë²• ë“±ì€ ë°˜ë“œì‹œ get_shuttle_bus_info í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.""",
            "parameters": {
                "type": "object",
                "required": [
                "user_input"
                ],
                "properties": {
                "user_input": {
                    "type": "string",
                    "description": "User's search query input(conversation context will be automatically added)"
                }
                },
                "additionalProperties": False
            }
            },
            {
            "type": "function",
            "name": "get_halla_cafeteria_menu",
            "description": "ì›ì£¼ í•œë¼ëŒ€í•™êµ í•™ìƒì‹ë‹¹ê³¼ êµì§ì›ì‹ë‹¹ì˜ ë©”ë‰´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ì£¼ê°„ ì‹ë‹¨ í˜ì´ì§€ì—ì„œ íŠ¹ì • ë‚ ì§œ/ë¼ë‹ˆì˜ ë©”ë‰´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. í•™ìƒì‹ë‹¹(/kr/211/)ê³¼ êµì§ì›ì‹ë‹¹(/kr/212/) ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "required": ["date"],
                "properties": {
                    "date": {
                        "type": "string",
                        "description": """ë°˜ë“œì‹œ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ ì „ë‹¬í•˜ì„¸ìš”.
                                ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì§ì ‘ ê³„ì‚°:
                                - "ì˜¤ëŠ˜" â†’ ì˜¤ëŠ˜ ë‚ ì§œ 
                                - "ë‚´ì¼" â†’ ì˜¤ëŠ˜+1ì¼
                                - "ëª¨ë ˆ" â†’ ì˜¤ëŠ˜+2ì¼
                                - "ê¸€í”¼/ê·¸ì„í”¼" â†’ ì˜¤ëŠ˜+3ì¼
                                - "ê·¸ê¸€í”¼" â†’ ì˜¤ëŠ˜+4ì¼
                                - "ë‹¤ìŒì£¼ ì›”ìš”ì¼" â†’ í•´ë‹¹ ë‚ ì§œ ê³„ì‚°
                                ì‚¬ìš©ìê°€ ì–´ë–¤ í‘œí˜„ì„ ì“°ë“  YYYY-MM-DDë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬.""",
                    },
                    "meal": {
                        "type": "string",
                        "enum": ["ì¡°ì‹", "ì¤‘ì‹", "ì„ì‹"],
                        "description": "ì¡°íšŒí•  ë¼ë‹ˆ. ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ë¼ë‹ˆë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.",
                    },
                    "cafeteria_type": {
                        "type": "string",
                        "enum": ["í•™ìƒ", "êµì§ì›"],
                        "description": "ì‹ë‹¹ ì¢…ë¥˜. 'í•™ìƒ' ë˜ëŠ” 'êµì§ì›'. ê¸°ë³¸ê°’ì€ 'í•™ìƒ'ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ 'êµì§ì›', 'êµìˆ˜', 'ì§ì›' ë“±ì˜ í‚¤ì›Œë“œë¥¼ ì–¸ê¸‰í•˜ë©´ 'êµì§ì›'ì„ ì„ íƒí•˜ì„¸ìš”.",
                    }
                },
                "additionalProperties": False
             }
            },
            {
            "type": "function",
            "name": "get_halla_academic_calendar",
            "description": "í•œë¼ëŒ€í•™êµ í•™ì‚¬ì¼ì •ì„ ì¡°íšŒí•©ë‹ˆë‹¤. íŠ¹ì • ì›”ì˜ í•™ì‚¬ ì¼ì •(ê°œê°•, ì¢…ê°•, ì‹œí—˜, ë°©í•™ ë“±)ì„ ì œê³µí•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "required": [],
                "properties": {
                    "month": {
                        "type": "string",
                        "description": """ì¡°íšŒí•  ì›”ì„ ì§€ì •í•©ë‹ˆë‹¤.
                            í—ˆìš© í˜•ì‹:
                            - ìƒëŒ€ ì›”: "ì´ë²ˆë‹¬", "ë‹¤ìŒë‹¬", "ì§€ë‚œë‹¬"
                            - ì ˆëŒ€ ì›”: "3ì›”", "12ì›”" (ì˜¬í•´ ê¸°ì¤€)
                            - YYYY-MM í˜•ì‹: "2025-03"
                            - YYYYë…„ MMì›”: "2025ë…„ 3ì›”"
                            - ìˆ«ì: "3", "12" (1~12ëŠ” ì›”ë¡œ í•´ì„)
                            ê¸°ë³¸ê°’: í˜„ì¬ ì›”""",
                    }
                },
                "additionalProperties": False
            }
            },
            {
            "type": "function",
            "name": "get_shuttle_bus_info",
            "description": """í•œë¼ëŒ€í•™êµ í†µí•™ë²„ìŠ¤(ì…”í‹€ë²„ìŠ¤) ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì „ìš© í•¨ìˆ˜ì…ë‹ˆë‹¤.

            âš ï¸ ì´ í•¨ìˆ˜ë¥¼ ë°˜ë“œì‹œ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°:
            - 'í†µí•™ë²„ìŠ¤', 'ì…”í‹€ë²„ìŠ¤', 'ìŠ¤ì¿¨ë²„ìŠ¤' ê´€ë ¨ ì§ˆë¬¸
            - 'ë“±êµ', 'í•˜êµ' ì‹œê°„ ë¬¸ì˜
            - 'ì›ì£¼ì—­', 'ë§Œì¢…ì—­', 'ì²­ì†”', 'ì‹œì™¸ë²„ìŠ¤í„°ë¯¸ë„' ë“± ì›ì£¼ ì‹œë‚´ ì¶œë°œì§€
            - 'ì„œìš¸', 'ìˆ˜ì›', 'ì—¬ì£¼', 'ì ì‹¤', 'ê°•ë³€', 'ë…¸ì›' ë“± ì‹œì™¸ ì¶œë°œì§€
            - ë²„ìŠ¤ íƒ‘ìŠ¹ ìœ„ì¹˜, ì‹œê°„í‘œ, ë…¸ì„ , ì˜ˆì•½ ë°©ë²•, ìš”ê¸ˆ ì§ˆë¬¸

            âš ï¸ í†µí•™ë²„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ì€ ì¸í„°ë„· ê²€ìƒ‰ì´ ì•„ë‹Œ ì´ í•¨ìˆ˜ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.

            ì§€ì› ì •ë³´:
            - ì‹œë‚´ë²„ìŠ¤: ë§Œì¢…ì—­, ëŒ€ëª…ì›, ì‹œì™¸ë²„ìŠ¤í„°ë¯¸ë„, ë¬´ì‹¤ë™, ì›ì£¼ì—­, ì²­ì†”ì•„íŒŒíŠ¸, í•œêµ­ê°€ìŠ¤ê³µì‚¬, ì˜¤ì„±ë§ˆì„, ì˜¤í˜ë¼ì›¨ë”©í™€
            - ì‹œì™¸ë²„ìŠ¤: ì„œìš¸(ì ì‹¤,ê°•ë³€,ìƒë´‰,ì²œí˜¸,ë…¸ì›), ìˆ˜ì›/ì—¬ì£¼(ë¼ë§ˆë‹¤í˜¸í…”,ì•„ì£¼ëŒ€,ì˜í†µ,ê¸°í¥,ì—¬ì£¼ì—­)
            - ì´ìš©ì•ˆë‚´: ì˜ˆì•½ë°©ë²•, ì·¨ì†Œë°©ë²•, ìš”ê¸ˆ, ì ë¦½ê¸ˆ""",
            "parameters": {
                "type": "object",
                "required": ["user_query"],
                "properties": {
                    "user_query": {
                        "type": "string",
                        "description": "ì‚¬ìš©ìì˜ í†µí•™ë²„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ ì›ë¬¸. ì˜ˆ: 'ìˆ˜ì› í•˜êµì‹œê°„', 'ì›ì£¼ì—­ ë“±êµ ë²„ìŠ¤', 'ì„œìš¸ í†µí•™ë²„ìŠ¤ ì˜ˆì•½'"
                    }
                },
                "additionalProperties": False
            }
            },



    ]

# --- ê³µì§€ ì¹´í…Œê³ ë¦¬ LLM ë¶„ë¥˜ê¸° ---
async def _classify_notice_category_llm(user_input: str, context_info: str | None = None, token_counter=None) -> str | None:
    """ì‚¬ìš©ì ì…ë ¥ì´ ì–´ë–¤ ê³µì§€ì‚¬í•­ ì¹´í…Œê³ ë¦¬ì¸ì§€ LLMìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ì¹´í…Œê³ ë¦¬ ë¬¸ìì—´ì„ ë°˜í™˜.
    ë°˜í™˜ ê°€ëŠ¥ ê°’: "í•™ì‚¬ê³µì§€", "ë¹„êµê³¼ê³µì§€", "ì¥í•™ê³µì§€", "ì¼ë°˜ê³µì§€", "í•´ë‹¹ì—†ìŒ". ì¸ì‹ ì‹¤íŒ¨ ì‹œ None.
    """
    try:
        allowed = ["í•™ì‚¬ê³µì§€", "ë¹„êµê³¼ê³µì§€", "ì¥í•™ê³µì§€", "ì¼ë°˜ê³µì§€", "í•´ë‹¹ì—†ìŒ"]
        prompt = (
            "ë‹¤ìŒ ì‚¬ìš©ìì˜ ìš”ì²­ì´ í•œë¼ëŒ€í•™êµ 'ê³µì§€' ì¤‘ ì–´ë–¤ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ”ì§€ í•˜ë‚˜ë§Œ ì„ íƒí•´ ë‹µí•˜ì„¸ìš”.\n"
            "ì¹´í…Œê³ ë¦¬: í•™ì‚¬ê³µì§€ | ë¹„êµê³¼ê³µì§€ | ì¥í•™ê³µì§€ | ì¼ë°˜ê³µì§€ | í•´ë‹¹ì—†ìŒ\n"
            "ê·œì¹™:\n"
            "- ì •í™•íˆ ìœ„ì˜ ë‹¨ì–´ ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ë§, ì„¤ëª…, ë”°ì˜´í‘œ ì—†ì´.\n"
            f"ì‚¬ìš©ì ì…ë ¥: {user_input}\n"
            f"ëŒ€í™” ë¬¸ë§¥: {context_info or '(ì—†ìŒ)'}\n\n"
            "ì •ë‹µ:"
        )

        # LLM Managerë¥¼ í†µí•´ Provider ì„ íƒ (êµì²´ ê°€ëŠ¥)
        provider = get_provider("category")
        messages = [{
            "role": "user",
            "content": [{"type": "input_text", "text": prompt}],
        }]
        raw, usage = await provider.simple_completion(messages)
        raw = raw.strip()

        # âœ… API usage ê¸°ë°˜ í† í° ê³„ì‚°
        if token_counter and usage:
            token_counter.update_from_api_usage(
                usage=usage,
                role="category",
                model=provider.get_model_name(),
                category="function"
            )
        
        logger.debug(f"ê³µì§€ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ê¸° ì›ë¬¸: {raw}")
        # ì •ê·œí™” ë° ì„ íƒ
        text_norm = raw.replace(" ", "").replace("\n", "")
        for a in allowed:
            if a in text_norm:
                return a
        logger.debug(f"[_classify_notice_category_llm] âš ï¸ No matching category found in response: {text_norm}")
        return None
    except Exception as e:
        logger.warning(f"[_classify_notice_category_llm] âŒ Error: {e}")
        logger.debug(f"[_classify_notice_category_llm] user_input: {user_input}")
        logger.debug(f"[_classify_notice_category_llm] context_info: {context_info}")
        return None

# --- ê·œì¹™ ê¸°ë°˜ ì‚¬ì´íŠ¸ ì„ í˜¸ ë¼ìš°íŒ… ---
async def _prefer_halla_site_query(user_input: str, context_info: str | None = None, token_counter=None) -> str | None:
    """íŠ¹ì • ìš”êµ¬ì‚¬í•­ì¼ ë•Œ í•œë¼ëŒ€ íŠ¹ì • í˜ì´ì§€ë¥¼ ìš°ì„  íƒìƒ‰í•˜ë„ë¡ ê²€ìƒ‰ì–´ë¥¼ êµ¬ì„±.
    ë§¤ì¹­ë˜ë©´ URLê³¼ site í•„í„°ë¥¼ í¬í•¨í•œ ì¿¼ë¦¬ë¥¼ ë°˜í™˜, ì—†ìœ¼ë©´ None.
    """
    base = (context_info or "")
    text = f"{user_input}\n{base}".lower()

    # ë©”ë‰´/í•™ì‹ ë¼ìš°íŒ…
    menu_keywords = ["í•™ì‹", "ì‹ë‹¨", "ë©”ë‰´", "ì ì‹¬", "ì €ë…", "ì˜¤ëŠ˜ ë©”ë‰´"]
    if any(k in text for k in menu_keywords):
        url = "https://www.halla.ac.kr/kr/211/subview.do"
        return f"site:halla.ac.kr {url} {user_input}"

    # ê³µì§€ ë¼ìš°íŒ…: LLM ë¶„ë¥˜ ê¸°ë°˜ â†’ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°±
    category = await _classify_notice_category_llm(user_input, context_info, token_counter)
    category_to_url = {
        "í•™ì‚¬ê³µì§€": "https://www.halla.ac.kr/kr/242/subview.do",
        "ë¹„êµê³¼ê³µì§€": "https://www.halla.ac.kr/kr/243/subview.do",
        "ì¥í•™ê³µì§€": "https://www.halla.ac.kr/kr/244/subview.do",
        "ì¼ë°˜ê³µì§€": "https://www.halla.ac.kr/kr/241/subview.do",
    }
    if category and category != "í•´ë‹¹ì—†ìŒ":
        url = category_to_url.get(category)
        if url:
            return f"site:halla.ac.kr {url} {user_input}"

    # í´ë°±: ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­
    if "í•™ì‚¬ê³µì§€" in text:
        url = "https://www.halla.ac.kr/kr/242/subview.do"
        return f"{user_input} site:halla.ac.kr {url} "
    if "ë¹„êµê³¼" in text or "ë¹„êµê³¼ê³µì§€" in text:
        url = "https://www.halla.ac.kr/kr/243/subview.do"
        return f"{user_input} site:halla.ac.kr {url}"
    if "ì¥í•™" in text:
        url = "https://www.halla.ac.kr/kr/244/subview.do"
        return f"{user_input} site:halla.ac.kr {url} "
    if "ì¼ë°˜ê³µì§€" in text or "ê³µì§€" in text:
        url = "https://www.halla.ac.kr/kr/241/subview.do"
        return f"{user_input} site:halla.ac.kr {url}"

    # ë¯¸ë§¤ì¹­ ì‹œ ë¼ìš°íŒ… ì—†ìŒ
    return None

async def search_internet(user_input: str, chat_context=None, token_counter=None) -> str:
    start_ts = time.time()
    logger.debug(f"[WEB][START] query='{user_input}' chat_ctx={'Y' if chat_context else 'N'}")
    try:
        # ëŒ€í™” ë¬¸ë§¥ ì²˜ë¦¬: ìµœê·¼ 2ê°œë§Œ ì‚¬ìš©
        if chat_context:
            logger.debug("[WEB] context available -> trimming recent messages")
            # system ì—­í•  ì œì™¸í•œ ë©”ì‹œì§€ë§Œ í•„í„°ë§
            non_system_messages = [m for m in chat_context if m.get('role') != 'system']
            
            # ìµœê·¼ 2ê°œë§Œ ì„ íƒ
            recent_messages = non_system_messages[-2:] if len(non_system_messages) >= 2 else non_system_messages
            
            # ëŒ€í™” ë¬¸ë§¥ êµ¬ì„±
            if len(recent_messages) == 0:
                context_info = "ìµœê·¼ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤"
                logger.debug("[WEB] No recent conversation history")
            elif len(recent_messages) == 1:
                context_info = f"{recent_messages[0].get('role','unknown')}: {recent_messages[0].get('content','')}"
                logger.debug(f"[WEB] Using 1 recent message for context")
            else:  # len(recent_messages) == 2
                context_info = "\n".join([
                    f"{m.get('role','unknown')}: {m.get('content','')}" for m in recent_messages
                ])
                logger.debug(f"[WEB] Using 2 recent messages for context")
        else:
            recent_messages = []
            context_info = "ìµœê·¼ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤"
            logger.debug("[WEB] No chat_context provided")

        preferred = await _prefer_halla_site_query(user_input, context_info if context_info else None, token_counter)
        
        # í˜„ì¬ ë‚ ì§œ ì •ë³´ ì¶”ê°€
        current_date = datetime.now()
        date_str = current_date.strftime("%Yë…„ %mì›” %dì¼")
        year_str = current_date.strftime("%Y")
        
        # ê³µì§€ì‚¬í•­ ê´€ë ¨ ê²€ìƒ‰ì¸ì§€ íŒë‹¨
        is_notice_query = any(keyword in user_input.lower() for keyword in ["ê³µì§€", "notice", "ì•Œë¦¼", "announcement"])
        
        # LLM ì—ì´ì „íŠ¸ë¡œ ê²€ìƒ‰ì–´ ì¬ì‘ì„± (context_info í¬í•¨)
        rewrite_prompt = (
            f"[í˜„ì¬ ë‚ ì§œ] {date_str} ({year_str}ë…„)\n"
            f"[ì‚¬ìš©ì ìš”ì²­] {user_input}\n"
            f"[ëŒ€í™” ë¬¸ë§¥] {context_info or 'ì—†ìŒ'}\n\n"
            "**ì¤‘ìš”**: ê²€ìƒ‰ ì—”ì§„ì— ì§ì ‘ ì…ë ¥í•  ìˆœìˆ˜í•œ ê²€ìƒ‰ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…, ì•ˆë‚´ë¬¸, ì¶”ê°€ ì„¤ëª… ì ˆëŒ€ ê¸ˆì§€.\n\n"
            "ê²€ìƒ‰ì–´ ì‘ì„± ê·œì¹™:\n"
            "1. site:halla.ac.kr í•„ìˆ˜ í¬í•¨\n"
        )
        
        # ê³µì§€ì‚¬í•­ ê²€ìƒ‰ì´ë©´ í•­ìƒ í˜„ì¬ ì—°ë„ í¬í•¨
        if is_notice_query:
            rewrite_prompt += (
                f"2. ë°˜ë“œì‹œ í˜„ì¬ ì—°ë„({year_str}ë…„) í¬í•¨\n"
                "3. ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ê²€ìƒ‰ì–´ë¡œë§Œ êµ¬ì„± (í•œ ì¤„)\n"
                "4. ì¶œë ¥ ì˜ˆì‹œ: 'site:halla.ac.kr 2025ë…„ í•™ì‚¬ê³µì§€'\n"
            )
        else:
            rewrite_prompt += (
                f"2. 'ìµœì‹ ', 'ìµœê·¼' í‚¤ì›Œë“œ ë°œê²¬ ì‹œ í˜„ì¬ ì—°ë„({year_str}ë…„) í¬í•¨\n"
                "3. ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ê²€ìƒ‰ì–´ë¡œë§Œ êµ¬ì„± (í•œ ì¤„)\n"
                "4. ì¶œë ¥ ì˜ˆì‹œ: 'site:halla.ac.kr í‚¤ì›Œë“œ'\n"
            )
        
        # preferredê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì •ë³´ë¡œ í™œìš©
        if preferred:
            rewrite_prompt += f"\n[ì¶”ì²œ ê²€ìƒ‰ì–´] {preferred}\nìœ„ ê²€ìƒ‰ì–´ë¥¼ ì°¸ê³ í•˜ë˜, ìˆœìˆ˜ ê²€ìƒ‰ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
        
        rewrite_prompt += "\n**ì¶œë ¥**: ê²€ìƒ‰ì–´ë§Œ í•œ ì¤„ë¡œ ì‘ì„± (ì„¤ëª… ê¸ˆì§€)"
        
        provider = get_provider("search_rewrite")
        messages = [{"role": "user", "content": [{"type": "input_text", "text": rewrite_prompt}]}]
        search_text, usage = await provider.simple_completion(messages)
        search_text = search_text.strip()

        # âœ… API usage ê¸°ë°˜ í† í° ê³„ì‚°
        if token_counter and usage:
            token_counter.update_from_api_usage(
                usage=usage,
                role="search_rewrite",
                model=provider.get_model_name(),
                category="function"
            )
        logger.debug(f"[WEB] final_search_text='{search_text}'")
        logger.debug(f"[WEB][ğŸ” ì‹¤ì œ ê²€ìƒ‰ì–´] '{search_text}'")
        logger.debug(f"[WEB][DEBUG] ì´ ê²€ìƒ‰ì–´ë¡œ OpenAI web_search_preview APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤")

        context_input = [{
            "role": "user",
            "content": [{"type": "input_text", "text": search_text}]
        }]
        
        logger.debug(f"[WEB][DEBUG] Request payload - model: {model.advanced}")
        logger.debug(f"[WEB][DEBUG] Request payload - search_text: '{search_text}'")
        logger.debug(f"[WEB][DEBUG] Request payload - tools: web_search_preview")

        call_ts = time.time()
        response = client.responses.create(
            model=model.advanced,
            input=context_input,
            text={"format": {"type": "text"}},
            reasoning={},
            tools=[{
                "type": "web_search_preview",
                "user_location": {"type": "approximate", "country": "KR"},
                "search_context_size": "medium"
            }],
            tool_choice={"type": "web_search_preview"},
            temperature=1,
            max_output_tokens=2048,
            top_p=1,
            store=True
        )
        logger.debug(f"[WEB] openai.responses.create elapsed={time.time()-call_ts:.2f}s total={time.time()-start_ts:.2f}s")
        logger.debug(f"[WEB][DEBUG] Response object type: {type(response)}")
        logger.debug(f"[WEB][DEBUG] Response has output: {hasattr(response, 'output')}")
        if hasattr(response, 'output'):
            logger.debug(f"[WEB][DEBUG] Output length: {len(response.output) if response.output else 0}")
            logger.debug(f"[WEB][DEBUG] Output types: {[getattr(item, 'type', 'unknown') for item in response.output] if response.output else []}")

        # âœ… API usage ì¶”ì  (web_search ì—­í• )
        if token_counter:
            if hasattr(response, 'usage') and response.usage:
                # API usage ì •ë³´ ì¶”ì¶œ
                input_tok = getattr(response.usage, "input_tokens", 0)
                output_tok = getattr(response.usage, "output_tokens", 0)

                # reasoning_tokens ì¶”ì¶œ (í•„ìš”ì‹œ)
                reasoning_tok = 0
                if hasattr(response.usage, 'output_tokens_details') and response.usage.output_tokens_details:
                    reasoning_tok = getattr(response.usage.output_tokens_details, 'reasoning_tokens', 0)

                # total_tokens ê³„ì‚°
                total_tok = getattr(response.usage, "total_tokens", input_tok + output_tok)

                usage_data = {
                    "input_tokens": input_tok,
                    "output_tokens": output_tok,
                    "reasoning_tokens": reasoning_tok,
                    "total_tokens": total_tok,
                }

                token_counter.update_from_api_usage(
                    usage=usage_data,
                    role="web_search",
                    model=model.advanced,  # gpt-4.1
                    category="function",
                    replace=False
                )
                logger.debug(f"[TokenTrack][web_search] âœ… API usage tracked: input={input_tok}, output={output_tok}, reasoning={reasoning_tok}")
            else:
                logger.debug(f"[TokenTrack][web_search] âš ï¸ No API usage available")

        did_call = any(getattr(item, "type", None) == "web_search_call" for item in getattr(response, "output", []))
        logger.debug(f"[WEB] search_call_performed={did_call}")
        
        # ğŸ“Š Output ì•„ì´í…œ ìƒì„¸ ë””ë²„ê¹…
        if hasattr(response, 'output') and response.output:
            logger.debug(f"[WEB][DEBUG] === Output Items Detail ===")
            for idx, item in enumerate(response.output):
                item_type = getattr(item, 'type', 'unknown')
                logger.debug(f"[WEB][DEBUG] Item[{idx}]: type={item_type}")
                if item_type == "web_search_call":
                    logger.debug(f"[WEB][DEBUG]   - web_search_call detected")
                elif item_type == "message":
                    content_count = len(getattr(item, 'content', [])) if hasattr(item, 'content') else 0
                    logger.debug(f"[WEB][DEBUG]   - message with {content_count} content blocks")

        message = next((item for item in response.output if getattr(item, "type", None) == "message"), None)
        logger.debug(f"[WEB][DEBUG] Message found: {message is not None}")
        if not message:
            logger.debug(f"[WEB][ERROR] âŒ No message in output")
            return "âŒ GPT ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # Content blocks ë””ë²„ê¹…
        content_blocks = getattr(message, 'content', [])
        logger.debug(f"[WEB][DEBUG] Content blocks count: {len(content_blocks)}")
        for idx, block in enumerate(content_blocks):
            block_type = getattr(block, 'type', 'unknown')
            logger.debug(f"[WEB][DEBUG] Content[{idx}]: type={block_type}")
        
        content_block = next((block for block in message.content if getattr(block, "type", None) == "output_text"), None)
        logger.debug(f"[WEB][DEBUG] Output_text block found: {content_block is not None}")
        if not content_block:
            logger.debug(f"[WEB][ERROR] âŒ No output_text in content blocks")
            return "âŒ GPT ì‘ë‹µ ë‚´ output_text í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        output_text = getattr(content_block, "text", "").strip()
        logger.debug(f"[WEB][DEBUG] Output text length: {len(output_text)}")
        logger.debug(f"[WEB][DEBUG] Output text preview: {output_text[:200] if output_text else '(empty)'}...")
        
        annotations = getattr(content_block, "annotations", [])
        logger.debug(f"[WEB][DEBUG] Annotations count: {len(annotations)}")
        logger.debug(f"[WEB][DEBUG] Annotations count: {len(annotations)}")
        
        citations = []
        for idx, a in enumerate(annotations):
            ann_type = getattr(a, "type", None)
            logger.debug(f"[WEB][DEBUG] Annotation[{idx}]: type={ann_type}")
            if ann_type == "url_citation":
                title = getattr(a, "title", "ì¶œì²˜")
                url = getattr(a, "url", "")
                logger.debug(f"[WEB][DEBUG]   - Citation: title='{title}', url='{url}'")
                if url:
                    citations.append(f"[{title}]({url})")
        
        logger.debug(f"[WEB][DEBUG] Total citations extracted: {len(citations)}")
        
        result = output_text
        if citations:
            result += "\n\nğŸ“ ì¶œì²˜:\n" + "\n".join(citations)
            logger.debug(f"[WEB][DEBUG] Citations added to result")
        else:
            logger.debug(f"[WEB][DEBUG] âš ï¸ No citations found")
        
        logger.debug(f"[WEB][DEBUG] Final result length: {len(result)}")
        logger.debug(f"[WEB][END] âœ… success total_elapsed={time.time()-start_ts:.2f}s")
        return result + "\n[WEB_METADATA]elapsed={:.2f}s did_call={}".format(time.time()-start_ts, did_call)
    except Exception as e:
        logger.debug(f"[WEB][ERROR] âŒ Exception occurred: {e} total_elapsed={time.time()-start_ts:.2f}s")
        logger.debug(f"[WEB][ERROR] user_input: {user_input}")
        logger.debug(f"[WEB][ERROR] chat_context: {chat_context is not None}")
        import traceback
        traceback.print_exc()
        return f"ğŸš¨ ì›¹ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"


def _parse_date_input(date_text: Optional[str]) -> datetime.date:
    today = datetime.now().date()
    if not date_text:
        return today
    s = str(date_text).strip()
    # ìƒëŒ€ ë‚ ì§œ ì§€ì›
    if s in ("ì˜¤ëŠ˜", "today"):
        return today
    if s in ("ë‚´ì¼", "tomorrow"):
        return today + timedelta(days=1)
    if s in ("ì–´ì œ", "yesterday"):
        return today - timedelta(days=1)
    if s in ("ëª¨ë ˆ", "day after tomorrow"):
        return today + timedelta(days=2)
    if s in ("ê¸€í”¼", "3 days later"):
        return today + timedelta(days=3)
    # Normalize separators and parse flexibly (YYYY.M.D or YYYY.MM.DD)
    s_norm = s.replace("/", ".").replace("-", ".")
    parts = s_norm.split(".")
    if len(parts) == 3 and all(p.isdigit() for p in parts):
        y, m, d = map(int, parts)
        return datetime(year=y, month=m, day=d).date()
    # í•œêµ­ì–´ í‘œê¸°: 9ì›” 7ì¼ (ì—°ë„ ìƒëµ ì‹œ ì˜¬í•´)
    m = re.search(r"(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼", s)
    if m:
        y = today.year
        month = int(m.group(1))
        day = int(m.group(2))
        return datetime(year=y, month=month, day=day).date()
    raise ValueError("ë‚ ì§œ í˜•ì‹ì€ YYYY-MM-DD / YYYY.M.D / 'ì˜¤ëŠ˜/ë‚´ì¼/ì–´ì œ'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")


async def get_halla_cafeteria_menu(date: Optional[str] = None, meal: Optional[str] = None, cafeteria_type: Optional[str] = None) -> str:
    """ì›ì£¼ í•œë¼ëŒ€ ì‹ë‹¹(í•™ìƒì‹ë‹¹/êµì§ì›ì‹ë‹¹) ì£¼ê°„ ì‹ë‹¨ í˜ì´ì§€ë¥¼ íŒŒì‹±í•˜ì—¬ íŠ¹ì • ë‚ ì§œ/ë¼ë‹ˆ ë©”ë‰´ë¥¼ ë°˜í™˜.

    Args:
        date: ì¡°íšŒí•  ë‚ ì§œ ("ì˜¤ëŠ˜", "ë‚´ì¼", "YYYY-MM-DD" ë“±)
        meal: ì¡°íšŒí•  ë¼ë‹ˆ ("ì¡°ì‹", "ì¤‘ì‹", "ì„ì‹", Noneì´ë©´ ì „ì²´)
        cafeteria_type: ì‹ë‹¹ ì¢…ë¥˜ ('í•™ìƒ' ë˜ëŠ” 'êµì§ì›', ê¸°ë³¸ê°’: 'í•™ìƒ')

    ì œí•œ: ì„œë²„ê°€ ì£¼ì°¨ ë³€ê²½ì„ JS/í¼ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ ê³¼ê±°/ë¯¸ë˜ ì£¼ ì„ íƒì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ. ì´ ê²½ìš° í˜„ì¬ ì£¼ë§Œ ë°˜í™˜.
    """
    # cafeteria_type ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •
    if cafeteria_type is None or cafeteria_type not in ["í•™ìƒ", "êµì§ì›"]:
        cafeteria_type = "í•™ìƒ"
    
    t0 = time.time()
    logger.debug(f"[CAF][START] date={date} meal={meal} cafeteria_type={cafeteria_type}")
    try:
        target_date = _parse_date_input(date)
    except Exception as e:
        logger.debug(f"[CAF][ERROR] âŒ date-parse exception: {e}")
        logger.debug(f"[CAF][ERROR] date input value: {date}")
        import traceback
        traceback.print_exc()
        return f"âŒ ë‚ ì§œ í•´ì„ ì‹¤íŒ¨: {e}"

    # URL ë¶„ê¸°: êµì§ì›ì‹ë‹¹ì€ /kr/212/, í•™ìƒì‹ë‹¹ì€ /kr/211/
    if cafeteria_type == "êµì§ì›":
        url = "https://www.halla.ac.kr/kr/212/subview.do"
    else:
        url = "https://www.halla.ac.kr/kr/211/subview.do"
    try:
        net_t = time.time()

        # User-Agent í—¤ë” ì¶”ê°€ (ë´‡ ì°¨ë‹¨ ë°©ì§€)
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }

        async with httpx.AsyncClient() as client:
            resp = await client.get(url, headers=headers, timeout=60.0)
            resp.raise_for_status()
            html_content = resp.text

        # ì—ëŸ¬ HTML ê°ì§€ (403 Forbidden ë“±)
        if "403 Forbidden" in html_content or "<title>403" in html_content:
            logger.debug(f"[CAF][ERROR] 403 Forbidden detected in response body")
            return f"âŒ í˜ì´ì§€ ì ‘ê·¼ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

        logger.debug(f"[CAF] fetch ok elapsed={time.time()-net_t:.2f}s status={resp.status_code}")
    except Exception as e:
        logger.debug(f"[CAF][ERROR] âŒ fetch exception: {e}")
        logger.debug(f"[CAF][ERROR] url: {url}")
        logger.debug(f"[CAF][ERROR] cafeteria_type: {cafeteria_type}")
        import traceback
        traceback.print_exc()
        return f"âŒ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}"

    soup = BeautifulSoup(html_content, "html.parser")

    # ì£¼ê°„ ë²”ìœ„ í…ìŠ¤íŠ¸ ì°¾ê¸° (ì˜ˆ: 2025.08.25 ~ 2025.08.31)
    text = soup.get_text("\n", strip=True)
    m = re.search(r"(\d{4}\.\d{2}\.\d{2})\s*~\s*(\d{4}\.\d{2}\.\d{2})", text)
    week_start = week_end = None
    if m:
        try:
            week_start = datetime.strptime(m.group(1), "%Y.%m.%d").date()
            week_end = datetime.strptime(m.group(2), "%Y.%m.%d").date()
        except Exception:
            pass

    # í˜„ì¬ ì£¼ í™•ì¸ ë° ëŒ€ìƒ ë‚ ì§œê°€ í•´ë‹¹ ì£¼ì— í¬í•¨ë˜ëŠ”ì§€ ì²´í¬
    if week_start and week_end and not (week_start <= target_date <= week_end):
        # ë‹¤ë¥¸ ì£¼ì¼ ê²½ìš°, ì„œë²„ê°€ íŒŒë¼ë¯¸í„° ì—†ì´ í˜„ì¬ ì£¼ë§Œ ì œê³µí•˜ë©´ í•œê³„ ì•ˆë‚´
        info = f"í˜„ì¬ í˜ì´ì§€ëŠ” {week_start}~{week_end} ì£¼ê°„ ì‹ë‹¨ì…ë‹ˆë‹¤."
        return info + " ì›í•˜ëŠ” ë‚ ì§œëŠ” ë‹¤ë¥¸ ì£¼ì…ë‹ˆë‹¤. í˜ì´ì§€ê°€ ì£¼ì°¨ íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•˜ì§€ ì•Šì•„ í˜„ì¬ ì£¼ë§Œ ì¡°íšŒ ê°€ëŠ¥í•©ë‹ˆë‹¤: " + url

    # í…Œì´ë¸” íƒìƒ‰: ìš”ì¼ í—¤ë”ì™€ ë¼ë‹ˆ ë¼ë²¨ì´ ìˆëŠ” í‘œë¥¼ ì°¾ì•„ íŒŒì‹±
    tables = soup.find_all("table")

    days = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
    weekday_idx = target_date.weekday()  # 0=ì›”
    target_day_label = days[weekday_idx]

    def clean(txt: str) -> str:
        return re.sub(r"\s+", " ", txt).strip()

    def pick_table_and_parse() -> dict:
        # ë°˜í™˜: {"ì¡°ì‹": str|None, "ì¤‘ì‹": str|None, "ì„ì‹": str|None}
        result = {"ì¡°ì‹": None, "ì¤‘ì‹": None, "ì„ì‹": None}
        for tbl in tables:
            rows = tbl.find_all("tr")
            if not rows:
                continue
            # 1) ìš”ì¼ ì—´ ì¸ë±ìŠ¤ ë§¤í•‘ ì°¾ê¸° (í—¤ë” 1~2í–‰ì„ ì‚´í´ë´„)
            day_col_index = None
            header_candidates = rows[:2] if len(rows) >= 2 else rows[:1]
            for hdr in header_candidates:
                cells = hdr.find_all(["th", "td"])
                for i, c in enumerate(cells):
                    txt = clean(c.get_text())
                    if target_day_label in txt or (txt.endswith("ìš”ì¼") and target_day_label in txt):
                        day_col_index = i
                        break
                if day_col_index is not None:
                    break

            # ì¼ë¶€ í‘œëŠ” ì²« ì—´ì´ 'êµ¬ë¶„', ì´í›„ ì›”~ì¼ì´ë¯€ë¡œ day_col_indexë¥¼ ëª» ì°¾ìœ¼ë©´ ì›”~ì¼ íŒ¨í„´ìœ¼ë¡œ ì¶”ì •
            if day_col_index is None:
                # í—¤ë” í–‰ì—ì„œ ì›”~ì¼ì´ ì—°ì†ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸
                for hdr in header_candidates:
                    cells = [clean(c.get_text()) for c in hdr.find_all(["th", "td"])]
                    if any(d in "".join(cells) for d in days):
                        # ê¸°ë³¸ì ìœ¼ë¡œ ì²« ì—´ì´ ë¼ë²¨, ì´í›„ ì›”=1, í™”=2 ...ë¡œ ê°€ì •
                        day_col_index = 1 + weekday_idx
                        break

            if day_col_index is None:
                continue

            # 2) ë¼ë‹ˆ ë¼ë²¨ í–‰ì„ ì°¾ì•„ í•´ë‹¹ ìš”ì¼ ì—´ì˜ ì…€ì„ ì¶”ì¶œ
            for tr in rows:
                cells = tr.find_all(["th", "td"])
                if not cells:
                    continue
                label = clean(cells[0].get_text()) if cells else ""
                # ë¼ë‹ˆëª…ì€ ë³€í˜•ë  ìˆ˜ ìˆì–´ ë¶€ë¶„ ì¼ì¹˜ í—ˆìš© (ì˜ˆ: ì¤‘ì‹(11:30~13:30))
                for meal_label in list(result.keys()):
                    if meal_label in label:
                        # ìš”ì¼ ì—´ì´ ë²”ìœ„ ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
                        if len(cells) > day_col_index:
                            result[meal_label] = clean(cells[day_col_index].get_text())
            # í•˜ë‚˜ë¼ë„ ìˆ˜ì§‘ë˜ì—ˆìœ¼ë©´ ì´ í…Œì´ë¸”ì„ ì±„íƒ
            if any(v for v in result.values()):
                return result
        return result

    parse_t = time.time()
    found = pick_table_and_parse()
    logger.debug(f"[CAF] primary-parse elapsed={time.time()-parse_t:.2f}s result={found}")

    # í´ë°±: í‘œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ë¼ì¸ ê¸°ë°˜ ì¶”ë¡ (ë¶€ì •í™•í•  ìˆ˜ ìˆìŒ)
    if all(v is None for v in found.values()):
        lines = [l for l in text.split("\n") if l]
        # ë§¤ìš° ë‹¨ìˆœ ì¶”ì •: 'ì¤‘ì‹ | ...' ê°™ì€ ë¼ì¸ì´ ìˆìœ¼ë©´ ê·¸ ë‹¤ìŒ í† í°ë“¤ì„ ì‚¬ìš©
        for key in list(found.keys()):
            for ln in lines:
                if key in ln and "|" in ln:
                    # íŒŒì´í”„ êµ¬ë¶„ìœ¼ë¡œ ë¶„í•´ í›„ ìš”ì¼ ì¸ë±ìŠ¤ ì‚¬ìš©
                    parts = [clean(p) for p in ln.split("|")]
                    # parts ì˜ˆ: [ë¼ë²¨, ì¡°ì‹, ì›”, í™”, ìˆ˜, ...] í˜•íƒœì¼ ìˆ˜ ìˆìŒ â†’ ì›”ì´ partsì—ì„œ ì–´ë””ì— ìˆëŠ”ì§€ ë™ì ìœ¼ë¡œ íƒìƒ‰
                    try:
                        # ì›”~ì¼ ì¤‘ target_day_labelì˜ ì²« ë“±ì¥ ìœ„ì¹˜ë¥¼ ì°¾ìŒ
                        day_pos = None
                        for i, token in enumerate(parts):
                            if token.startswith(target_day_label):
                                day_pos = i
                                break
                        if day_pos is None:
                            # ê¸°ë³¸ ì˜¤í”„ì…‹ ê°€ì •: [ë¼ë²¨, ë¼ë‹ˆ, ì›”, í™”, ìˆ˜, ...]
                            base = 2
                            day_pos = base + weekday_idx
                        if len(parts) > day_pos:
                            found[key] = parts[day_pos]
                    except Exception:
                        pass
                        break

    # ê²°ê³¼ êµ¬ì„±
    day_label = target_day_label
    cafeteria_label = "êµì§ì›ì‹ë‹¹" if cafeteria_type == "êµì§ì›" else "í•™ìƒì‹ë‹¹"
    header = f"í•œë¼ëŒ€ {cafeteria_label} ì‹ë‹¨ ({target_date} {day_label})"

    if meal in ("ì¡°ì‹", "ì¤‘ì‹", "ì„ì‹"):
        val = found.get(meal)
        if not val:
            out = header + f"\n[{meal}] ì •ë³´ ì—†ìŒ\nì¶”ê°€ ì‚¬í•­: ì›ë¬¸: {url}"
            logger.debug(f"[CAF][END] elapsed={time.time()-t0:.2f}s meal-miss")
            return out
        out = header + f"\n[{meal}] {val}\nì¶”ê°€ ì‚¬í•­: ì›ë¬¸: {url}"
        logger.debug(f"[CAF][END] elapsed={time.time()-t0:.2f}s meal-hit")
        return out

    # 3ë¼ ëª¨ë‘ ë°˜í™˜
    lines_out = []
    for k in ["ì¡°ì‹", "ì¤‘ì‹", "ì„ì‹"]:
        v = found.get(k)
        lines_out.append(f"[{k}] {v if v else 'ì •ë³´ ì—†ìŒ'}")
    out = header + "\n" + "\n".join(lines_out) + f"\nì¶”ê°€ ì‚¬í•­: ì›ë¬¸: {url}"
    logger.debug(f"[CAF][END] elapsed={time.time()-t0:.2f}s all-meals")
    return out


def _parse_month_input(month_text: Optional[str]) -> tuple:
    """ì›” ì…ë ¥ì„ íŒŒì‹±í•˜ì—¬ (ë…„, ì›”) íŠœí”Œ ë°˜í™˜

    Args:
        month_text: ì›” ì…ë ¥ ("ì´ë²ˆë‹¬", "ë‹¤ìŒë‹¬", "2025-03", "3ì›”" ë“±)

    Returns:
        (year, month) íŠœí”Œ
    """
    today = datetime.now().date()

    if not month_text:
        return (today.year, today.month)

    s = str(month_text).strip()

    # ìƒëŒ€ ì›” ì§€ì›
    if s in ("ì´ë²ˆë‹¬", "ì´ë²ˆ ë‹¬", "í˜„ì¬", "this month"):
        return (today.year, today.month)
    if s in ("ë‹¤ìŒë‹¬", "ë‹¤ìŒ ë‹¬", "next month"):
        next_month = today.replace(day=1) + timedelta(days=32)
        return (next_month.year, next_month.month)
    if s in ("ì§€ë‚œë‹¬", "ì§€ë‚œ ë‹¬", "last month"):
        prev_month = today.replace(day=1) - timedelta(days=1)
        return (prev_month.year, prev_month.month)

    # YYYY-MM í˜•ì‹
    if re.match(r"^\d{4}-\d{1,2}$", s):
        parts = s.split("-")
        return (int(parts[0]), int(parts[1]))

    # YYYYë…„ MMì›” í˜•ì‹
    m = re.search(r"(\d{4})ë…„\s*(\d{1,2})ì›”", s)
    if m:
        return (int(m.group(1)), int(m.group(2)))

    # MMì›” í˜•ì‹ (ì˜¬í•´)
    m = re.search(r"(\d{1,2})ì›”", s)
    if m:
        return (today.year, int(m.group(1)))

    # ìˆ«ìë§Œ (1~12: ì›”, ê·¸ ì™¸: í˜„ì¬ ì›”)
    if s.isdigit():
        num = int(s)
        if 1 <= num <= 12:
            return (today.year, num)

    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í˜„ì¬ ì›”
    return (today.year, today.month)


async def get_halla_academic_calendar(month: Optional[str] = None) -> str:
    """í•œë¼ëŒ€í•™êµ í•™ì‚¬ì¼ì • ì¡°íšŒ

    Args:
        month: ì¡°íšŒí•  ì›” ("ì´ë²ˆë‹¬", "ë‹¤ìŒë‹¬", "2025-03", "3ì›”" ë“±)

    Returns:
        í•™ì‚¬ì¼ì • ì •ë³´ ë¬¸ìì—´
    """
    t0 = time.time()
    logger.debug(f"[CALENDAR][START] month={month}")

    try:
        year, month_num = _parse_month_input(month)
    except Exception as e:
        logger.debug(f"[CALENDAR][ERROR] âŒ month-parse exception: {e}")
        logger.debug(f"[CALENDAR][ERROR] month input value: {month}")
        import traceback
        traceback.print_exc()
        return f"âŒ ì›” í•´ì„ ì‹¤íŒ¨: {e}"

    url = "https://www.halla.ac.kr/kr/100/subview.do"

    try:
        net_t = time.time()
        # íŠ¹ì • ë…„ì›” ì¡°íšŒ ì‹œë„ (íŒŒë¼ë¯¸í„° ì „ë‹¬)
        params = {"year": str(year), "month": str(month_num)}

        # User-Agent í—¤ë” ì¶”ê°€ (ë´‡ ì°¨ë‹¨ ë°©ì§€)
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }

        async with httpx.AsyncClient() as client:
            resp = await client.get(url, params=params, headers=headers, timeout=60.0)
            resp.raise_for_status()
            html_content = resp.text

        # ì—ëŸ¬ HTML ê°ì§€ (403 Forbidden ë“±)
        if "403 Forbidden" in html_content or "<title>403" in html_content:
            logger.debug(f"[CALENDAR][ERROR] 403 Forbidden detected in response body")
            return f"âŒ í˜ì´ì§€ ì ‘ê·¼ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

        logger.debug(f"[CALENDAR] fetch ok elapsed={time.time()-net_t:.2f}s status={resp.status_code}")
    except Exception as e:
        logger.debug(f"[CALENDAR][ERROR] âŒ fetch exception: {e}")
        logger.debug(f"[CALENDAR][ERROR] url: {url}")
        logger.debug(f"[CALENDAR][ERROR] params: {params}")
        import traceback
        traceback.print_exc()
        return f"âŒ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}"

    soup = BeautifulSoup(html_content, "html.parser")

    schedules = []

    # ë°©ë²• 1: ul íƒœê·¸ì—ì„œ li í•­ëª© ì°¾ê¸°
    ul_tags = soup.find_all("ul")
    for ul in ul_tags:
        li_items = ul.find_all("li")
        for li in li_items:
            text = li.get_text("\n", strip=True)
            # "MM.DD" íŒ¨í„´ì´ í¬í•¨ëœ lië§Œ ì²˜ë¦¬
            if re.search(r"\d{1,2}\.\d{1,2}", text):
                # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€ê²½í•˜ê³  ì •ë¦¬
                cleaned = " ".join(text.split())
                if len(cleaned) > 5:  # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ
                    schedules.append(cleaned)

    # ë°©ë²• 2: ulì—ì„œ ëª» ì°¾ì•˜ìœ¼ë©´, ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ë§¤ì¹­
    if not schedules:
        text = soup.get_text("\n", strip=False)
        lines = text.split("\n")

        # "MM.DD" íŒ¨í„´ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ ì°¾ê¸°
        schedule_pattern = re.compile(r"(\d{1,2}\.\d{1,2})")

        i = 0
        while i < len(lines):
            line = lines[i].strip()
            match = schedule_pattern.match(line)

            if match:
                # ë‚ ì§œ ë¼ì¸ ë°œê²¬
                date_str = match.group(1)

                # ë‹¤ìŒ ë¼ì¸ì´ ì¼ì • ë‚´ìš©ì¼ ê°€ëŠ¥ì„±
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()

                    # ë²”ìœ„ ë‚ ì§œ ì²´í¬ (ì˜ˆ: "11.24 - 11.25")
                    if next_line.startswith("-") and i + 2 < len(lines):
                        # "- 11.25" í˜•íƒœ
                        range_match = re.match(r"-\s*(\d{1,2}\.\d{1,2})", next_line)
                        if range_match:
                            end_date = range_match.group(1)
                            date_str = f"{date_str} - {end_date}"
                            i += 1  # ë‹¤ìŒ ë¼ì¸ ê±´ë„ˆë›°ê¸°

                            # ê·¸ ë‹¤ìŒ ë¼ì¸ì´ ì¼ì • ë‚´ìš©
                            if i + 1 < len(lines):
                                next_line = lines[i + 1].strip()

                    # ì¼ì • ë‚´ìš©ì¸ì§€ í™•ì¸ (ë‚ ì§œ íŒ¨í„´ì´ ì•„ë‹ˆê³ , ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸)
                    if next_line and not schedule_pattern.match(next_line) and len(next_line) > 1:
                        schedules.append(f"{date_str}: {next_line}")
                        i += 1  # ë‹¤ìŒ ë¼ì¸ ê±´ë„ˆë›°ê¸°

            i += 1

    # ê²°ê³¼ êµ¬ì„±
    header = f"í•œë¼ëŒ€ í•™ì‚¬ì¼ì • ({year}ë…„ {month_num}ì›”)"

    if not schedules:
        out = header + f"\në“±ë¡ëœ ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤.\nì›ë¬¸: {url}"
        logger.debug(f"[CALENDAR][END] elapsed={time.time()-t0:.2f}s no-schedule")
        return out

    out = header + "\n" + "\n".join(schedules) + f"\n\nì›ë¬¸: {url}"
    logger.debug(f"[CALENDAR][END] elapsed={time.time()-t0:.2f}s schedules={len(schedules)}")
    return out


# í†µí•™ë²„ìŠ¤ ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_shuttle_bus_service = None

def _get_shuttle_bus_service():
    """ShuttleBusService ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _shuttle_bus_service
    if _shuttle_bus_service is None:
        _shuttle_bus_service = ShuttleBusService()
    return _shuttle_bus_service


async def get_shuttle_bus_info(user_query: str, chat_context=None, token_counter=None) -> str:
    """í•œë¼ëŒ€í•™êµ í†µí•™ë²„ìŠ¤ ì •ë³´ ì œê³µ

    Args:
        user_query: ì‚¬ìš©ìì˜ í†µí•™ë²„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸
        chat_context: ëŒ€í™” ë¬¸ë§¥ (ìµœê·¼ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸)
        token_counter: í† í° ì¹´ìš´í„°

    Returns:
        í†µí•™ë²„ìŠ¤ ì •ë³´ ì‘ë‹µ ë¬¸ìì—´
    """
    start_ts = time.time()
    logger.debug(f"[SHUTTLE][START] query='{user_query}' chat_ctx={'Y' if chat_context else 'N'}")

    try:
        # ëŒ€í™” ë¬¸ë§¥ ì¶”ì¶œ
        if chat_context:
            recent_messages = chat_context[-4:]
            context_info = "\n".join([
                f"{m.get('role','unknown')}: {m.get('content','')}"
                for m in recent_messages if m.get('role') != 'system'
            ])
        else:
            context_info = ""

        # ShuttleBusService ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        service = _get_shuttle_bus_service()

        # 1ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        category = await service.classify_category(
            user_input=user_query,
            context_info=context_info,
            token_counter=token_counter
        )

        logger.debug(f"[SHUTTLE] category={category}")

        # í†µí•™ë²„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ì´ ì•„ë‹Œ ê²½ìš°
        if category == "not_shuttle_bus":
            elapsed = time.time() - start_ts
            logger.debug(f"[SHUTTLE][END] elapsed={elapsed:.2f}s result=not_shuttle_bus")
            return "í†µí•™ë²„ìŠ¤ì™€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤. ì‹œë‚´ë²„ìŠ¤, ì‹œì™¸ë²„ìŠ¤ ì‹œê°„í‘œ, ì˜ˆì•½ ë°©ë²• ë“±ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."

        # 2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ë³„ ì •ë³´ ì¶”ì¶œ
        shuttle_info = service.get_info_by_category(category, user_query)
        logger.debug(f"[SHUTTLE] info extracted len={len(shuttle_info)}")

        # 3ë‹¨ê³„: ì‘ë‹µ ìƒì„±
        response = await service.generate_response(
            user_input=user_query,
            shuttle_info=shuttle_info,
            token_counter=token_counter
        )

        elapsed = time.time() - start_ts
        logger.debug(f"[SHUTTLE][END] elapsed={elapsed:.2f}s response_len={len(response)}")

        return response

    except Exception as e:
        elapsed = time.time() - start_ts
        logger.debug(f"[SHUTTLE][ERROR] elapsed={elapsed:.2f}s error={e}")
        import traceback
        traceback.print_exc()
        return f"âŒ í†µí•™ë²„ìŠ¤ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


class FunctionCalling:
    def __init__(self, model, available_functions=None, token_counter=None):
        self.model = model
        self.token_counter = token_counter
        default_functions = {
            "search_internet": search_internet,
            "get_halla_cafeteria_menu": get_halla_cafeteria_menu,
            "get_halla_academic_calendar": get_halla_academic_calendar,
            "get_shuttle_bus_info": get_shuttle_bus_info,
        }

        if available_functions:
            default_functions.update(available_functions)

        self.available_functions = default_functions
       
    async def analyze(self, user_message, tools):
        """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ í•¨ìˆ˜ì™€ íŒë‹¨ ê·¼ê±°ë¥¼ ë°˜í™˜

        Returns:
            dict: {
                "reasoning": str (íŒë‹¨ ê·¼ê±°),
                "output": list (í•¨ìˆ˜ í˜¸ì¶œ ëª©ë¡, ê¸°ì¡´ response.output í˜•ì‹)
            }
        """
        if not user_message or user_message.strip() == "":
            return {
                "reasoning": "ì…ë ¥ì´ ë¹„ì–´ìˆì–´ í•¨ìˆ˜ë¥¼ ì„ íƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "output": []
            }
        
        # 1ë‹¨ê³„: LLMìœ¼ë¡œ í•¨ìˆ˜ ì„ íƒ ì´ìœ  ìƒì„± (structured output)
        reasoning = None
        try:
            from app.ai.chatbot import character
            from app.ai.llm import get_provider
            
            prompt = [
                {"role": "system", "content": character.decide_function},
                {"role": "user", "content": user_message},
            ]
            
            schema = {
                "type": "object",
                "properties": {
                    "reasoning": {"type": "string"},
                    "selected_tools": {
                        "type": "array",
                        "items": {"type": "string"}
                    }
                },
                "required": ["reasoning", "selected_tools"],
                "additionalProperties": False,
            }
            
            provider = get_provider("function_analyze")
            raw, usage = await provider.structured_completion(prompt, schema)
            raw = raw.strip()

            # âœ… API usage ê¸°ë°˜ í† í° ê³„ì‚°
            if self.token_counter and usage:
                self.token_counter.update_from_api_usage(
                    usage=usage,
                    role="function_analyze",
                    model=provider.get_model_name(),
                    category="function"
                )
            
            if raw:
                payload = json.loads(raw)
                reasoning = payload.get("reasoning", "").strip() or None
                selected_tools = payload.get("selected_tools", [])
        except Exception as e:
            logger.debug(f"[ANALYZER][analyze] âŒ Reasoning generation failed: {e}")
            logger.debug(f"[ANALYZER][analyze] user_message: {user_message}")
            import traceback
            traceback.print_exc()
            reasoning = f"ì¶”ë¡  ìƒì„± ì‹¤íŒ¨ ({e})"
            selected_tools = []  # exception ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ì„¤ì •

        # 2ë‹¨ê³„: ê¸°ì¡´ í•¨ìˆ˜ í˜¸ì¶œ ë¶„ì„ (OpenAI API)

        # í˜„ì¬ ë‚ ì§œ ì •ë³´ ìƒì„±
        current_date = datetime.now()
        date_info = current_date.strftime("%Yë…„ %mì›” %dì¼ (%A)")
        weekday_map = {
            "Monday": "ì›”ìš”ì¼", "Tuesday": "í™”ìš”ì¼", "Wednesday": "ìˆ˜ìš”ì¼",
            "Thursday": "ëª©ìš”ì¼", "Friday": "ê¸ˆìš”ì¼", "Saturday": "í† ìš”ì¼", "Sunday": "ì¼ìš”ì¼"
        }
        weekday_kr = weekday_map.get(current_date.strftime("%A"), "")
        date_info = current_date.strftime(f"%Yë…„ %mì›” %dì¼ ({weekday_kr})")

        structured_input = [
            {
                "role": "system",
                "content": f"""í˜„ì¬ ë‚ ì§œ: {date_info}

[í•„ìˆ˜ ê·œì¹™]
ëª¨ë“  ë‚ ì§œë¥¼ ë°˜ë“œì‹œ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”.
- ì˜¤ëŠ˜ â†’ {current_date.strftime("%Y-%m-%d")}
- ë‚´ì¼ â†’ ì˜¤ëŠ˜+1ì¼ ê³„ì‚°
- ëª¨ë ˆ â†’ ì˜¤ëŠ˜+2ì¼ ê³„ì‚°
- ê¸€í”¼/ê·¸ì„í”¼ â†’ ì˜¤ëŠ˜+3ì¼ ê³„ì‚°
- ê·¸ê¸€í”¼ â†’ ì˜¤ëŠ˜+4ì¼ ê³„ì‚°
- "Nì¼ í›„" â†’ ì˜¤ëŠ˜+Nì¼ ê³„ì‚°
- "ë‹¤ìŒì£¼ ì›”ìš”ì¼" â†’ í•´ë‹¹ ë‚ ì§œ ê³„ì‚°
- ë‚ ì§œ ë¯¸ì–¸ê¸‰ â†’ ì˜¤ëŠ˜ ë‚ ì§œ ì¶œë ¥

ì‚¬ìš©ìê°€ ì˜¤íƒ€(ì•¼ëª¨ë ˆ, ê·¸ì„í”¼ ë“±)ë¥¼ ì“°ë”ë¼ë„ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ YYYY-MM-DDë¡œ ë³€í™˜."""
            },
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": user_message}
                ],
            }
        ]
        try:
            response = client.responses.create(
                model=model.o3_mini,
                input=structured_input,
                tools=tools,
                tool_choice="auto",
            )

            if self.token_counter and hasattr(response, 'usage') and response.usage:
                usage_data = {
                    "input_tokens": getattr(response.usage, "input_tokens", 0),
                    "output_tokens": getattr(response.usage, "output_tokens", 0),
                    "total_tokens": getattr(response.usage, "total_tokens", 0),
                    "reasoning_tokens": getattr(response.usage.output_tokens_details, 'reasoning_tokens', 0) if hasattr(response.usage, 'output_tokens_details') else 0,
                }
                self.token_counter.update_from_api_usage(
                    usage=usage_data,
                    role="function_calling",
                    model=model.o3_mini,
                    category="function",
                    replace=False
                )

            return {
                "reasoning": reasoning,
                "selected_tools": selected_tools,  # reasoningì—ì„œ ì„ íƒëœ ë„êµ¬ ëª©ë¡ ì¶”ê°€
                "output": response.output
            }
        except Exception as e:
            logger.debug(f"[ANALYZER][analyze] âŒ OpenAI API call failed: {e}")
            logger.debug(f"[ANALYZER][analyze] user_message: {user_message}")
            logger.debug(f"[ANALYZER][analyze] model: {model.o3_mini}")
            import traceback
            traceback.print_exc()
            return {
                "reasoning": reasoning,
                "selected_tools": selected_tools,
                "output": []
            }
    

###   ë ˆê±°ì‹œ def run(self, analyzed,context):
        ''' analyzed_dict: í•¨ìˆ˜ í˜¸ì¶œ ì •ë³´, context: í˜„ì¬ ë¬¸ë§¥'''
        context.append(analyzed)
        for tool_call in analyzed:
            if tool_call.get("type") != "function_call":
                continue
            function=tool_call["function"]
            func_name=function["name"]
            #ì‹¤ì œ í•¨ìˆ˜ì™€ ì—°ê²°
            func_to_call = self.available_functions[func_name]

            try:

                func_args=json.loads(function["arguments"])#ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜-> ë¬¸ìì—´ì´ jsoní˜•íƒœì…-> ì´ê±¸ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                
                if func_name == "search_internet":
                    # contextëŠ” ì´ë¯¸ run ë©”ì„œë“œì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ê³  ìˆìŒ
                    func_response = func_to_call(chat_context=context[:], **func_args)
                else:
                    func_response=func_to_call(**func_args)
                context.append({
                    "tool_call_id": tool_call["id"],
                    "role": "tool",
                    "name": func_name, 
                    "content": str(func_response),
                    "parallel_tool_calls": True
                })#ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¬¸ë§¥ì— ì¶”ê°€
  

            except Exception as e:
                logger.warning("Error occurred(run):",e)
                return makeup_response("[run ì˜¤ë¥˜ì…ë‹ˆë‹¤]")

        # í•¨ìˆ˜ ì‹¤í–‰ í›„ ìµœì¢… ì‘ë‹µ ìƒì„±
        response = client.responses.create(model=self.model, input=context)

        # âœ… API usage ì¶”ì  (function_calling ì—­í•  - ì¬í˜¸ì¶œ)
        if self.token_counter and hasattr(response, 'usage') and response.usage:
            usage_data = {
                "input_tokens": getattr(response.usage, "input_tokens", 0),
                "output_tokens": getattr(response.usage, "output_tokens", 0),
                "total_tokens": getattr(response.usage, "total_tokens", 0),
                "reasoning_tokens": getattr(response.usage.output_tokens_details, 'reasoning_tokens', 0) if hasattr(response.usage, 'output_tokens_details') else 0,
            }
            self.token_counter.update_from_api_usage(
                usage=usage_data,  # âœ… ìˆ˜ì •: usage_info â†’ usage
                role="function_calling",
                model=self.model,  # âœ… ì¶”ê°€: í•„ìˆ˜ íŒŒë¼ë¯¸í„°
                category="function",
                replace=False
            )

        return response.model_dump()
    ###
   
    def call_function(self, analyzed_dict):        
        func_name = analyzed_dict["function_call"]["name"]
        func_to_call = self.available_functions[func_name]                
        try:            
            func_args = json.loads(analyzed_dict["function_call"]["arguments"])
            func_response = func_to_call(**func_args)
            return str(func_response)
        except Exception as e:
            logger.warning("Error occurred(call_function):",e)
            return makeup_response("[call_function ì˜¤ë¥˜ì…ë‹ˆë‹¤]")
    