import os
import sys
from loding.documentLoding import documents, extract_chunks_finditer, extract_star_tables
from loding.mongodbConnect import insert_chunks_to_mongo, collection
from typing import List, Dict
from loding.vector_db_upload import upload_chunks_to_pinecone, index, get_embedding
from loding.vector_db_upload import pc, index_name
from pinecone import Pinecone

# ì˜¬ë°”ë¥¸ ì¸ë±ìŠ¤ ì—°ê²°
index = pc.Index(index_name)  # "halla-academic-index" ì‚¬ìš©

def test_full_pipeline():
    """PDF ë¡œë“œ â†’ ì²­í¬ ìƒì„± â†’ MongoDB ì €ì¥ â†’ Pinecone ì—…ë¡œë“œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    
    print("=" * 60)
    print("           ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # 1. ë¬¸ì„œ ë¡œë“œ í™•ì¸
    print(f"ğŸ“š 1ë‹¨ê³„: ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ - {len(documents)}ê°œ íŒŒì¼")
    
    # 2. ì²­í¬ ìƒì„±
    print("\nğŸ“ 2ë‹¨ê³„: ì²­í¬ ìƒì„± ì¤‘...")
    all_chunks: List[Dict] = []
    
    for i, doc in enumerate(documents):
        filename = doc.metadata.get('file_name', f'ë¬¸ì„œ_{i+1}')
        print(f"\nì²˜ë¦¬ ì¤‘: {filename}")
        
        # ì¡°ë¬¸ ì²­í¬ ìƒì„±
        law_chunks = extract_chunks_finditer(doc.text, filename)
        all_chunks.extend(law_chunks)
        
        # ë³„í‘œ ì²­í¬ ìƒì„±
        star_chunks = extract_star_tables(doc.text, filename, law_chunks)
        all_chunks.extend(star_chunks)
        
        print(f"âœ… {filename}: ì¡°ë¬¸ {len(law_chunks)}ê°œ + ë³„í‘œ {len(star_chunks)}ê°œ = ì´ {len(law_chunks) + len(star_chunks)}ê°œ ì²­í¬")
    
    print(f"\nğŸ“Š ì²­í¬ ìƒì„± ì™„ë£Œ: ì´ {len(all_chunks)}ê°œ")
    
    # 3. ì²­í¬ ìƒ˜í”Œ í™•ì¸
    print("\nğŸ“– 3ë‹¨ê³„: ìƒì„±ëœ ì²­í¬ ìƒ˜í”Œ (ì²« ë²ˆì§¸ ì²­í¬)")
    if all_chunks:
        sample_chunk = all_chunks[0]
        print("ë©”íƒ€ë°ì´í„°:")
        for key, value in sample_chunk['metadata'].items():
            print(f"   {key}: {value}")
        print(f"\në‚´ìš© (ê¸¸ì´: {len(sample_chunk['text'])} ë¬¸ì):")
        print("-" * 40)
        print(sample_chunk['text'][:200] + "..." if len(sample_chunk['text']) > 200 else sample_chunk['text'])
        print("-" * 40)
    
    # 4. MongoDB ì €ì¥
    print("\nğŸ’¾ 4ë‹¨ê³„: MongoDB ì €ì¥ ì¤‘...")
    insert_chunks_to_mongo(all_chunks)
    
    # 5. Pinecone ë²¡í„° DB ì—…ë¡œë“œ
    print("\nğŸš€ 5ë‹¨ê³„: Pinecone ë²¡í„° DB ì—…ë¡œë“œ ì¤‘...")
    try:
        # ì¡°ë¬¸ ì¹´í…Œê³ ë¦¬ ì—…ë¡œë“œ (ì˜ë¬¸ ì¹´í…Œê³ ë¦¬ëª… ì‚¬ìš©)
        upload_chunks_to_pinecone(category="law_articles")
        # ë³„í‘œ ì¹´í…Œê³ ë¦¬ ì—…ë¡œë“œ (ì˜ë¬¸ ì¹´í…Œê³ ë¦¬ëª… ì‚¬ìš©)
        upload_chunks_to_pinecone(category="appendix_tables")
        print("âœ… Pinecone ì—…ë¡œë“œ ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ Pinecone ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 6. ì €ì¥ ê²°ê³¼ í™•ì¸
    print("\nğŸ” 6ë‹¨ê³„: ì €ì¥ ê²°ê³¼ í™•ì¸")
    total_docs = collection.count_documents({})
    print(f"MongoDBì— ì €ì¥ëœ ì´ ë¬¸ì„œ ìˆ˜: {total_docs}ê°œ")
    
    # íŒŒì¼ë³„ ì €ì¥ ìˆ˜ í™•ì¸
    pipeline = [
        {"$group": {"_id": "$metadata.source_file", "count": {"$sum": 1}}},
        {"$sort": {"_id": 1}}
    ]
    file_counts = list(collection.aggregate(pipeline))
    print("\níŒŒì¼ë³„ ì €ì¥ëœ ì²­í¬ ìˆ˜:")
    for item in file_counts:
        print(f"   {item['_id']}: {item['count']}ê°œ")
    
    print("\nâœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return all_chunks

def test_mongodb_query():
    """MongoDBì—ì„œ ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
    
    print("\n" + "=" * 60)
    print("           MongoDB ì¡°íšŒ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ì¡°ë¬¸ íƒ€ì… ë¬¸ì„œ ì¡°íšŒ
    law_docs = list(collection.find({"metadata.category": "law_articles"}).limit(2))
    print(f"ğŸ“‹ ì¡°ë¬¸ íƒ€ì… ë¬¸ì„œ ìˆ˜: {collection.count_documents({'metadata.category': 'law_articles'})}ê°œ")
    
    if law_docs:
        print(f"\nì²« ë²ˆì§¸ ì¡°ë¬¸ ìƒ˜í”Œ:")
        doc = law_docs[0]
        print(f"   ì¡°ë¬¸ë²ˆí˜¸: {doc['metadata'].get('law_article_id', 'N/A')}")
        print(f"   ì œëª©: {doc['metadata'].get('title', 'N/A')}")
        print(f"   íŒŒì¼: {doc['metadata'].get('source_file', 'N/A')}")
    
    # ë³„í‘œ íƒ€ì… ë¬¸ì„œ ì¡°íšŒ
    star_docs = list(collection.find({"metadata.category": "appendix_tables"}).limit(2))
    print(f"\nğŸ“Œ ë³„í‘œ íƒ€ì… ë¬¸ì„œ ìˆ˜: {collection.count_documents({'metadata.category': 'appendix_tables'})}ê°œ")
    
    if star_docs:
        print(f"\nì²« ë²ˆì§¸ ë³„í‘œ ìƒ˜í”Œ:")
        doc = star_docs[0]
        print(f"   ë³„í‘œë²ˆí˜¸: {doc['metadata'].get('table_id', 'N/A')}")
        print(f"   ì—°ê²° ì¡°ë¬¸: {doc['metadata'].get('parent_law_article', 'N/A')}")
        print(f"   íŒŒì¼: {doc['metadata'].get('source_file', 'N/A')}")

def test_pinecone_vector_search():
    """Pinecone ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    
    print("\n" + "=" * 60)
    print("           Pinecone ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ì‚¬ìš©ìê°€ ì§ì ‘ ì¿¼ë¦¬ ì…ë ¥í•  ìˆ˜ ìˆë„ë¡ ê°œì„ 
    print("ê²€ìƒ‰ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ë¡œ í…ŒìŠ¤íŠ¸")
    print("2. ì§ì ‘ ì¿¼ë¦¬ ì…ë ¥")
    
    search_choice = input("\nì„ íƒ (1-2): ")
    
    if search_choice == "1":
        # ë¯¸ë¦¬ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_queries = [
            "í•™ì‚¬ ê´€ë¦¬ì— ê´€í•œ ê·œì •",
            "ë³„í‘œì— ê´€í•œ ë‚´ìš©",
            "ì™¸êµ­ëŒ€í•™ê³¼ì˜ í•™Â·ì„ì‚¬ ì—°ê³„ê³¼ì •"
        ]
    elif search_choice == "2":
        # ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬
        user_query = input("\nê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if user_query:
            test_queries = [user_query]
        else:
            print("âŒ ë¹ˆ ì¿¼ë¦¬ì…ë‹ˆë‹¤. ê¸°ë³¸ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            test_queries = ["í•™ì‚¬ ê´€ë¦¬ì— ê´€í•œ ê·œì •"]
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ê¸°ë³¸ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        test_queries = ["í•™ì‚¬ ê´€ë¦¬ì— ê´€í•œ ê·œì •"]
    
    for query in test_queries:
        print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = get_embedding(query)
            
            # ì¡°ë¬¸ ì¹´í…Œê³ ë¦¬ì—ì„œ ê²€ìƒ‰
            law_results = index.query(
                vector=query_embedding,
                top_k=3,
                namespace="law_articles",
                include_metadata=True
            )
            
            print(f"ğŸ“‹ ì¡°ë¬¸ ê²€ìƒ‰ ê²°ê³¼ ({len(law_results.matches)}ê°œ):")
            for i, match in enumerate(law_results.matches):
                print(f"   {i+1}. ìœ ì‚¬ë„: {match.score:.3f}")
                print(f"      ì¡°ë¬¸: {match.metadata.get('law_article_id', 'N/A')}")
                print(f"      ì œëª©: {match.metadata.get('title', 'N/A')}")
                print(f"      ë¯¸ë¦¬ë³´ê¸°: {match.metadata.get('text_preview', 'N/A')}")
            
            # ë³„í‘œ ì¹´í…Œê³ ë¦¬ì—ì„œ ê²€ìƒ‰
            star_results = index.query(
                vector=query_embedding,
                top_k=2,
                namespace="appendix_tables",
                include_metadata=True
            )
            
            print(f"\nğŸ“Œ ë³„í‘œ ê²€ìƒ‰ ê²°ê³¼ ({len(star_results.matches)}ê°œ):")
            for i, match in enumerate(star_results.matches):
                print(f"   {i+1}. ìœ ì‚¬ë„: {match.score:.3f}")
                print(f"      ë³„í‘œ: {match.metadata.get('table_id', 'N/A')}")
                print(f"      ì—°ê²° ì¡°ë¬¸: {match.metadata.get('parent_law_article', 'N/A')}")
                print(f"      ë¯¸ë¦¬ë³´ê¸°: {match.metadata.get('text_preview', 'N/A')}")
            
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        print("-" * 50)

def test_pinecone_stats():
    """Pinecone ì¸ë±ìŠ¤ í†µê³„ í™•ì¸"""
    
    print("\n" + "=" * 60)
    print("           Pinecone ì¸ë±ìŠ¤ í†µê³„")
    print("=" * 60)
    
    try:
        # ì¸ë±ìŠ¤ í†µê³„
        stats = index.describe_index_stats()
        print(f"ğŸ“Š ì´ ë²¡í„° ìˆ˜: {stats.total_vector_count}")
        print(f"ğŸ“Š ì¸ë±ìŠ¤ í¬ê¸°: {stats.index_fullness:.2%}")
        
        if stats.namespaces:
            print("\nğŸ“‹ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ ë²¡í„° ìˆ˜:")
            for namespace, info in stats.namespaces.items():
                print(f"   {namespace}: {info.vector_count}ê°œ")
        
    except Exception as e:
        print(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

def cleanup_test_data():
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚­ì œ"""
    
    print("\n" + "=" * 60)
    print("           í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚­ì œ")
    print("=" * 60)
    
    # ì‚­ì œ ì „ ë°ì´í„° ìˆ˜ í™•ì¸
    before_count = collection.count_documents({})
    print(f"ğŸ—‘ï¸ ì‚­ì œ ì „ ì´ ë¬¸ì„œ ìˆ˜: {before_count}ê°œ")
    
    if before_count == 0:
        print("âš ï¸ ì‚­ì œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì‚¬ìš©ì í™•ì¸
    response = input(f"\nì •ë§ë¡œ ëª¨ë“  í…ŒìŠ¤íŠ¸ ë°ì´í„°({before_count}ê°œ)ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
    
    if response.lower() == 'y':
        # ëª¨ë“  ë°ì´í„° ì‚­ì œ
        result = collection.delete_many({})
        print(f"âœ… ì‚­ì œ ì™„ë£Œ: {result.deleted_count}ê°œ ë¬¸ì„œ ì‚­ì œë¨")
        
        # ì‚­ì œ í›„ í™•ì¸
        after_count = collection.count_documents({})
        print(f"ğŸ” ì‚­ì œ í›„ ì´ ë¬¸ì„œ ìˆ˜: {after_count}ê°œ")
    else:
        print("âŒ ì‚­ì œ ì·¨ì†Œë¨")

def cleanup_pinecone_data():
    """Pinecone ë²¡í„° ë°ì´í„° ì‚­ì œ"""
    
    print("\n" + "=" * 60)
    print("           Pinecone ë°ì´í„° ì‚­ì œ")
    print("=" * 60)
    
    try:
        # í˜„ì¬ ë²¡í„° ìˆ˜ í™•ì¸
        stats = index.describe_index_stats()
        total_vectors = stats.total_vector_count
        
        if total_vectors == 0:
            print("âš ï¸ ì‚­ì œí•  ë²¡í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ—‘ï¸ ì‚­ì œ ëŒ€ìƒ ë²¡í„° ìˆ˜: {total_vectors}ê°œ")
        
        # ì‚¬ìš©ì í™•ì¸
        response = input(f"\nì •ë§ë¡œ ëª¨ë“  ë²¡í„° ë°ì´í„°({total_vectors}ê°œ)ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
        
        if response.lower() == 'y':
            # ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‚­ì œ
            namespaces = list(stats.namespaces.keys()) if stats.namespaces else ["default"]
            
            for namespace in namespaces:
                index.delete(delete_all=True, namespace=namespace)
                print(f"âœ… {namespace} ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‚­ì œ ì™„ë£Œ")
            
            print("âœ… ëª¨ë“  Pinecone ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
        else:
            print("âŒ ì‚­ì œ ì·¨ì†Œë¨")
            
    except Exception as e:
        print(f"âŒ ì‚­ì œ ì‹¤íŒ¨: {e}")

def debug_pinecone_data():
    """Pinecone ë°ì´í„° ìƒì„¸ ì§„ë‹¨"""
    
    print("\n" + "=" * 60)
    print("           Pinecone ë°ì´í„° ì§„ë‹¨")
    print("=" * 60)
    
    try:
        # 1. ì „ì²´ í†µê³„
        stats = index.describe_index_stats()
        print(f"ğŸ“Š ì´ ë²¡í„° ìˆ˜: {stats.total_vector_count}")
        
        # 2. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ ìƒì„¸ í™•ì¸
        if stats.namespaces:
            for namespace, info in stats.namespaces.items():
                print(f"\nğŸ“‹ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {namespace}")
                print(f"   ë²¡í„° ìˆ˜: {info.vector_count}ê°œ")
                
                # ê° ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ìƒ˜í”Œ ê²€ìƒ‰í•´ë³´ê¸°
                sample_results = index.query(
                    vector=[0.1] * 1536,  # ë”ë¯¸ ë²¡í„°ë¡œ ê²€ìƒ‰
                    top_k=1,
                    namespace=namespace,
                    include_metadata=True
                )
                
                if sample_results.matches:
                    sample = sample_results.matches[0]
                    print(f"   ìƒ˜í”Œ ë©”íƒ€ë°ì´í„°: {list(sample.metadata.keys())}")
                else:
                    print(f"   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        
        # 3. ì‹¤ì œ ì˜ë¯¸ìˆëŠ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ” ì‹¤ì œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
        query_embedding = get_embedding("ì œ1ì¡°")
        
        # law_articles ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê²€ìƒ‰
        law_results = index.query(
            vector=query_embedding,
            top_k=2,
            namespace="law_articles",
            include_metadata=True
        )
        print(f"law_articles ê²€ìƒ‰ ê²°ê³¼: {len(law_results.matches)}ê°œ")
        
        # appendix_tables ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê²€ìƒ‰ 
        try:
            star_results = index.query(
                vector=query_embedding,
                top_k=2,
                namespace="appendix_tables",
                include_metadata=True
            )
            print(f"appendix_tables ê²€ìƒ‰ ê²°ê³¼: {len(star_results.matches)}ê°œ")
        except Exception as e:
            print(f"appendix_tables ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            
    except Exception as e:
        print(f"âŒ ì§„ë‹¨ ì‹¤íŒ¨: {e}")

def check_pinecone_indexes():
    """Pinecone ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸"""
    
    print("\n" + "=" * 60)
    print("           Pinecone ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸")
    print("=" * 60)
    
    try:
        # 1. ì‚¬ìš© ê°€ëŠ¥í•œ ì¸ë±ìŠ¤ ëª©ë¡
        indexes = pc.list_indexes()
        print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì¸ë±ìŠ¤ ëª©ë¡:")
        for idx in indexes:
            print(f"   - ì´ë¦„: {idx.name}")
            print(f"     ìƒíƒœ: {idx.status.state}")
            print(f"     í˜¸ìŠ¤íŠ¸: {idx.host}")
            print(f"     ì°¨ì›: {idx.dimension}")
            print()
        
        # 2. í˜„ì¬ ì—°ê²°ëœ ì¸ë±ìŠ¤ ì •ë³´
        print(f"ğŸ”— í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì¸ë±ìŠ¤: {index_name}")
        
        # 3. ì¸ë±ìŠ¤ ìƒì„¸ ì •ë³´
        if index_name in [idx.name for idx in indexes]:
            index_info = pc.describe_index(index_name)
            print(f"âœ… ì¸ë±ìŠ¤ ìƒíƒœ: {index_info.status.state}")
            print(f"ğŸ“ í˜¸ìŠ¤íŠ¸ URL: {index_info.host}")
            print(f"ğŸ“ ë²¡í„° ì°¨ì›: {index_info.dimension}")
            print(f"ğŸ·ï¸ ë©”íŠ¸ë¦­: {index_info.metric}")
            print(f"â˜ï¸ í´ë¼ìš°ë“œ: {index_info.spec.serverless.cloud}")
            print(f"ğŸŒ ì§€ì—­: {index_info.spec.serverless.region}")
        else:
            print("âŒ ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            
    except Exception as e:
        print(f"âŒ ì¸ë±ìŠ¤ í™•ì¸ ì‹¤íŒ¨: {e}")

def list_all_namespaces():
    """ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ëª©ë¡ í™•ì¸"""
    
    print("\n" + "=" * 60)
    print("           ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ëª©ë¡ í™•ì¸")
    print("=" * 60)
    
    try:
        stats = index.describe_index_stats()
        
        if stats.namespaces:
            print("ğŸ“‹ ë°œê²¬ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤:")
            for namespace, info in stats.namespaces.items():
                print(f"   â€¢ '{namespace}': {info.vector_count}ê°œ ë²¡í„°")
                
                # ê° ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ìƒ˜í”Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                try:
                    sample_query = index.query(
                        vector=[0.1] * 1536,
                        top_k=1,
                        namespace=namespace,
                        include_metadata=True
                    )
                    
                    if sample_query.matches:
                        sample = sample_query.matches[0]
                        print(f"     ìƒ˜í”Œ ID: {sample.id}")
                        print(f"     ë©”íƒ€ë°ì´í„° í‚¤: {list(sample.metadata.keys())}")
                        if 'law_article_id' in sample.metadata:
                            print(f"     ì¡°ë¬¸: {sample.metadata.get('law_article_id')}")
                        if 'table_id' in sample.metadata:
                            print(f"     ë³„í‘œ: {sample.metadata.get('table_id')}")
                    print()
                        
                except Exception as e:
                    print(f"     âš ï¸ ìƒ˜í”Œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        else:
            print("âŒ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™•ì¸ ì‹¤íŒ¨: {e}")

def show_menu():
    """ë©”ë‰´ í‘œì‹œ"""
    print("\n" + "ğŸ¯" * 30)
    print("           í•œë¼ëŒ€í•™êµ LLM í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ")
    print("ğŸ¯" * 30)
    print()
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("   1. ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (PDF â†’ ì²­í¬ â†’ MongoDB â†’ Pinecone)")
    print("   2. MongoDB ì¡°íšŒ í…ŒìŠ¤íŠ¸")
    print("   3. Pinecone ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ âœ¨")
    print("   4. Pinecone ì¸ë±ìŠ¤ í†µê³„")
    print("   5. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚­ì œ (MongoDB)")
    print("   6. ë²¡í„° ë°ì´í„° ì‚­ì œ (Pinecone)")
    print("   7. Pinecone ë²¡í„° ì—…ë¡œë“œë§Œ ì‹¤í–‰ (MongoDBì— ìˆëŠ” ì²­í¬ë¥¼ Pineconeìœ¼ë¡œ ì—…ë¡œë“œ)")
    print("   8. Pinecone ë°ì´í„° ì§„ë‹¨")
    print("   9. Pinecone ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸")
    print("   10. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ëª©ë¡ í™•ì¸")
    print("   0. ì¢…ë£Œ")
    print()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ë¬´í•œ ë£¨í”„ë¡œ ê³„ì† í…ŒìŠ¤íŠ¸ ê°€ëŠ¥"""
    
    print("ğŸš€ í•œë¼ëŒ€í•™êµ LLM ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ í™˜ê²½ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
    
    while True:
        try:
            show_menu()
            choice = input("ğŸ‘‰ ì„ íƒ (0-10): ").strip()
            
            if choice == "0":
                print("\nğŸ‘‹ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!")
                break
            elif choice == "1":
                test_full_pipeline()
            elif choice == "2":
                test_mongodb_query()
            elif choice == "3":
                test_pinecone_vector_search()
            elif choice == "4":
                test_pinecone_stats()
            elif choice == "5":
                cleanup_test_data()
            elif choice == "6":
                cleanup_pinecone_data()
            elif choice == "7":
                # MongoDBì— ì €ì¥ëœ ì²­í¬ë§Œì„ Pineconeìœ¼ë¡œ ì—…ë¡œë“œí•˜ëŠ” ê°„ë‹¨ ì‹¤í–‰ ê²½ë¡œ
                print("\nğŸš€ Pinecone ë²¡í„° ì—…ë¡œë“œ (MongoDB -> Pinecone) ì‹œì‘")
                try:
                    upload_chunks_to_pinecone(category="law_articles")
                    upload_chunks_to_pinecone(category="appendix_tables")
                    print("âœ… Pinecone ì—…ë¡œë“œ ì™„ë£Œ!")
                except Exception as e:
                    print(f"âŒ Pinecone ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            elif choice == "8":
                debug_pinecone_data()
            elif choice == "9":
                check_pinecone_indexes()
            elif choice == "10":
                list_all_namespaces()
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 0-10 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            # ì‘ì—… ì™„ë£Œ í›„ ì‚¬ìš©ìì—ê²Œ ê³„ì†í• ì§€ ë¬¼ì–´ë³´ê¸°
            if choice != "0":
                print("\n" + "-" * 60)
                continue_choice = input("ê³„ì† í…ŒìŠ¤íŠ¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Enter: ê³„ì†, q: ì¢…ë£Œ): ").strip().lower()
                if continue_choice == 'q':
                    print("\nğŸ‘‹ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!")
                    break
                
        except KeyboardInterrupt:
            print("\n\nâš ï¸ Ctrl+Cë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            print("ê³„ì† ì§„í–‰í•˜ê±°ë‚˜ ì¢…ë£Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")

if __name__ == "__main__":
    main()

